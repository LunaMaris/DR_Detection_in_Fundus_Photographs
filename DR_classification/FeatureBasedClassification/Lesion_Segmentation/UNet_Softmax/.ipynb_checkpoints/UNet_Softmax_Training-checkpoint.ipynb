{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ga1Mx266ltfH"
   },
   "source": [
    "This script is used to perform lesion segmentation in fundus photographs. The lesions that can be segmented are hard exudates, soft exudates, microaneurysms and hemorrhages. The segmentation is based on a UNet, a CNN that takes an image as an input and that outputs a probability map indicating for every pixel the probability of belonging to a certain type of lesion or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4393,
     "status": "ok",
     "timestamp": 1596614177611,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "00738778653758640454"
     },
     "user_tz": -120
    },
    "id": "Gf8WnH-elznb",
    "outputId": "ffb11443-39db-4ee2-87e1-5d20d800137c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorlayer==1.11.1 in /usr/local/lib/python3.6/dist-packages (1.11.1)\n",
      "Requirement already satisfied: scikit-learn<0.21,>=0.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (0.20.4)\n",
      "Requirement already satisfied: matplotlib<3.1,>=2.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (3.0.3)\n",
      "Requirement already satisfied: wrapt<1.11,>=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.10.11)\n",
      "Requirement already satisfied: tqdm<4.29,>=4.23 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (4.28.1)\n",
      "Requirement already satisfied: progressbar2<3.39,>=3.38 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (3.38.0)\n",
      "Requirement already satisfied: requests<2.21,>=2.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (2.20.1)\n",
      "Requirement already satisfied: scikit-image<0.15,>=0.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (0.14.5)\n",
      "Requirement already satisfied: imageio<2.5,>=2.3 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (2.4.1)\n",
      "Requirement already satisfied: scipy<1.2,>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.1.0)\n",
      "Requirement already satisfied: numpy<1.16,>=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.15.4)\n",
      "Requirement already satisfied: lxml<4.3,>=4.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (4.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (1.2.0)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2<3.39,>=3.38->tensorlayer==1.11.1) (2.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from progressbar2<3.39,>=3.38->tensorlayer==1.11.1) (1.15.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (1.24.3)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (2.7)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (2.4)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (7.0.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (1.3.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (4.4.2)\n",
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorlayer==1.11.1\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9179,
     "status": "ok",
     "timestamp": 1596614182411,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "00738778653758640454"
     },
     "user_tz": -120
    },
    "id": "9eyAksxJOFsi",
    "outputId": "748fd5e6-ae6a-4b64-bf0c-2254a870df0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/core.py:39: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/pooling.py:66: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1.15.2\n",
      "1.11.1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import tensorlayer.layers as tll\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tl.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9161,
     "status": "ok",
     "timestamp": 1596614182412,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "00738778653758640454"
     },
     "user_tz": -120
    },
    "id": "M85RveB_uPv3",
    "outputId": "55a33a87-51f4-49f5-fcd8-351604ca04f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# read in train and test data in case Google DRIVE is used\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4SbTTqBltfN"
   },
   "outputs": [],
   "source": [
    "# read in the train and test data for a certain lesion type\n",
    "\n",
    "# Basepath depends on the lesion\n",
    "# LesionType = 'SoftExudates'\n",
    "LesionType = 'HardExudates'\n",
    "# LesionType = 'Microaneurysms'\n",
    "# LesionType = 'Hemorrhages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 96882,
     "status": "ok",
     "timestamp": 1596614270168,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "00738778653758640454"
     },
     "user_tz": -120
    },
    "id": "Na905WmrltfS",
    "outputId": "316a6545-561e-4719-e75d-afd34780b0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train images: (324, 512, 512, 3)\n",
      "Shape train annotations: (324, 512, 512)\n",
      "Shape test images: (156, 512, 512, 3)\n",
      "Shape test annotations: (156, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Basepath for Google DRIVE:\n",
    "# Basepath = '/content/drive/My Drive/Stage_ENT_Studios/Data/IDRiD/' + LesionType + '/Arrays/'\n",
    "\n",
    "# Basepath for Jupyter notebooks:\n",
    "Basepath = 'C:/Users/lunam/Documents/1steMaster/Stage/Data_FinalArrays/IDRiD/'+ LesionType+'/Arrays/'\n",
    "\n",
    "# train data\n",
    "train_images = np.float32(np.load(Basepath + 'train_images_Final.npy'))\n",
    "print('Shape train images: {}'.format(train_images.shape))\n",
    "\n",
    "train_annotations =  np.int32(np.load(Basepath + 'train_annotations_Final.npy'))\n",
    "# train_annotations = np.expand_dims(train_annotations, axis = 3)\n",
    "print('Shape train annotations: {}'.format(train_annotations.shape))\n",
    "\n",
    "# test data\n",
    "test_images = np.float32(np.load(Basepath + 'test_images_Final.npy'))\n",
    "print('Shape test images: {}'.format(test_images.shape))\n",
    "\n",
    "test_annotations = np.int32(np.load(Basepath + 'test_annotations_Final.npy'))\n",
    "# test_annotations = np.expand_dims(test_annotations, axis = 3)\n",
    "print('Shape test annotations: {}'.format(test_annotations.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWjV59oPltfZ"
   },
   "outputs": [],
   "source": [
    "# path to save the model and the tensorboard logs\n",
    "\n",
    "# Basepath for Google DRIVE:\n",
    "# base_path = '/content/drive/My Drive/Stage_ENT_Studios/Unet/Logs/'\n",
    "\n",
    "# Basepath for jupyter notebooks:\n",
    "base_path = 'C:/Users/lunam/Documents/1steMaster/Stage/Code_Final/DR_classification/FeatureBasedClassification/UNet_Softmax/Logs/'+LesionType+'/'\n",
    "\n",
    "# direction where the tensorboard files will be stored\n",
    "log_dir_tens = base_path + 'Tensorboard_Logs/'\n",
    "# direction where the trained models will be stored\n",
    "log_dir_model = base_path + 'Trained_Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05Xofm8P4hR9"
   },
   "outputs": [],
   "source": [
    "class BatchData():\n",
    "    '''\n",
    "    This class is used to create batches of images with their corresponding annotations\n",
    "    These batches can then be fed to the Unet\n",
    "    The numpy arrays of preprocessed images and corresponding annotations are given as an input to the class\n",
    "    '''\n",
    "    \n",
    "    # resetting all values in case a new batch dataset is created\n",
    "    images = []\n",
    "    annotations = []\n",
    "    batch_offset = 0\n",
    "    epochs_completed = 0 \n",
    "\n",
    "\n",
    "    def __init__(self, image_arrays, annotation_arrays):\n",
    "        \n",
    "        print(\"Initializing Batch Dataset Reader...\")\n",
    "        \n",
    "        self.images = image_arrays\n",
    "        self.annotations = annotation_arrays\n",
    "\n",
    "        # resize the annotations to indicate that there is only one channel in this case\n",
    "        self.annotations = np.expand_dims(self.annotations, 3)\n",
    "        # this makes a binary mask of the annotations, there where annotations has a pixel value above 0, the pixel value will be set to 1\n",
    "        # there where the pixel value is 0 or smaller, the pixel value is set to 0\n",
    "        self.annotations = np.where(self.annotations>0, 1, 0)\n",
    "        \n",
    "        print ('Shape images: {}'.format(self.images.shape))\n",
    "        print ('Shape annotations: {}'.format(self.annotations.shape))\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        '''\n",
    "        This function can be used to everytime find the next batch of images and corresponding annotations\n",
    "        The size of the batches is defined by the batch_size\n",
    "        '''\n",
    "        \n",
    "        # start image of the batch\n",
    "        start = self.batch_offset\n",
    "        # set the starting value for the next batch\n",
    "        self.batch_offset += batch_size \n",
    "        \n",
    "        # all data has already been used\n",
    "        if self.batch_offset > self.images.shape[0]:\n",
    "            \n",
    "            # images and annotations get shuffled randomly for the next epoch\n",
    "            perm = np.arange(self.images.shape[0])\n",
    "            np.random.shuffle(perm)\n",
    "            self.images = self.images[perm]\n",
    "            self.annotations = self.annotations[perm]\n",
    "            \n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self.batch_offset = batch_size\n",
    "        \n",
    "        # end image of the batch\n",
    "        end = self.batch_offset\n",
    "        \n",
    "        # return the images and corresponding annotations in this batch\n",
    "        return self.images[start:end], self.annotations[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55GrGQj34IK8"
   },
   "outputs": [],
   "source": [
    "def LoadBatchData(Train_Images, Train_Annotations, Test_Images, Test_Annotations):\n",
    "    '''\n",
    "    This function creates a batch dataset for the train and test set\n",
    "    '''\n",
    "    \n",
    "    # create a batchdataset for the train set\n",
    "    train_batch_data = BatchData(Train_Images, Train_Annotations)\n",
    "            \n",
    "    # create a batchdataset for the test set\n",
    "    test_batch_data = BatchData(Test_Images, Test_Annotations)\n",
    "            \n",
    "    # return the train and test batch dataset\n",
    "    return train_batch_data, test_batch_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FICWJHVxltfh"
   },
   "outputs": [],
   "source": [
    "# The UNet network\n",
    "def UNet(image, drop_prob = 0.1, init_filters = 64,  is_train = True):\n",
    "    '''This function defines the original UNet network'''\n",
    "    \n",
    "    # initialization of the weights\n",
    "    W_init = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "    # Unet network\n",
    "                \n",
    "    # LEFT part\n",
    "    # input layer\n",
    "    input_image = tl.layers.InputLayer(image)\n",
    "            \n",
    "    # Convolutional block 1\n",
    "    conv2d_1 = tl.layers.Conv2d(input_image, init_filters, (3, 3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_2 = tl.layers.Conv2d(conv2d_1, init_filters, (3, 3), act= tf.nn.relu, W_init= W_init)\n",
    "    pool_1 = tl.layers.MaxPool2d(conv2d_2, (2, 2), (2, 2), name= 'maxpool_1')\n",
    "    dropout_1 = tl.layers.DropoutLayer(pool_1, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 2\n",
    "    conv2d_3 = tl.layers.Conv2d(dropout_1, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_4 = tl.layers.Conv2d(conv2d_3, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    pool_2 = tl.layers.MaxPool2d(conv2d_4, (2,2), (2, 2), name='maxpool_2')\n",
    "    dropout_2 = tl.layers.DropoutLayer(pool_2, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 3\n",
    "    conv2d_5 = tl.layers.Conv2d(dropout_2, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_6 = tl.layers.Conv2d(conv2d_5, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    pool_3 = tl.layers.MaxPool2d(conv2d_6, (2,2), (2, 2), name='maxpool_3')\n",
    "    dropout_3 = tl.layers.DropoutLayer(pool_3, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 4\n",
    "    conv2d_7 = tl.layers.Conv2d(dropout_3, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_8 = tl.layers.Conv2d(conv2d_7, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    pool_4 = tl.layers.MaxPool2d(conv2d_8, (2,2), (2, 2), name='maxpool_4')\n",
    "    dropout_4 = tl.layers.DropoutLayer(pool_4, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # MIDDLE part\n",
    "    conv2d_9 = tl.layers.Conv2d(dropout_4, 16*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_10 = tl.layers.Conv2d(conv2d_9, 16*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "                \n",
    "                \n",
    "    # RIGHT part\n",
    "    # Convolutional block 1\n",
    "    upsampling_1 = tl.layers.UpSampling2dLayer(conv2d_10, (2,2))\n",
    "    concat_1 = tl.layers.ConcatLayer([upsampling_1, conv2d_8], 3)\n",
    "    dropout_5 = tl.layers.DropoutLayer(concat_1, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_11 = tl.layers.Conv2d(dropout_5, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_12 = tl.layers.Conv2d(conv2d_11, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "                \n",
    "    # Convolutional block 2\n",
    "    upsampling_2 = tl.layers.UpSampling2dLayer(conv2d_12, (2,2))\n",
    "    concat_2 = tl.layers.ConcatLayer([upsampling_2, conv2d_6], 3)\n",
    "    dropout_6 = tl.layers.DropoutLayer(concat_2, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_13 = tl.layers.Conv2d(dropout_6, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_14 = tl.layers.Conv2d(conv2d_13, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "            \n",
    "                \n",
    "    # Convolutional block 3\n",
    "    upsampling_3 = tl.layers.UpSampling2dLayer(conv2d_14, (2,2))\n",
    "    concat_3 = tl.layers.ConcatLayer([upsampling_3,conv2d_4], 3)\n",
    "    dropout_7 = tl.layers.DropoutLayer(concat_3, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_15 = tl.layers.Conv2d(dropout_7, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_16 = tl.layers.Conv2d(conv2d_15, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "                \n",
    "    # Convolutional block 4\n",
    "    upsampling_4 = tl.layers.UpSampling2dLayer(conv2d_16, (2,2))\n",
    "    concat_4 = tl.layers.ConcatLayer([upsampling_4,conv2d_2], 3)\n",
    "    dropout_8 = tl.layers.DropoutLayer(concat_4, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_17 = tl.layers.Conv2d(dropout_8, init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_18 = tl.layers.Conv2d(conv2d_17, init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "                \n",
    "                \n",
    "    # ouput layer\n",
    "    output_image = tl.layers.Conv2d(conv2d_18, 2, (1,1), W_init= W_init) \n",
    "\n",
    "    # logits tensor, often a step inbetween befor a softmax activation is applied (size im_size x im_size, 2)\n",
    "    logits = output_image.outputs\n",
    "\n",
    "    # the model\n",
    "    model = output_image\n",
    "\n",
    "    # a binary output map with size im_size x im_size can be found by applying the argmax operation\n",
    "    # this operation yields 0 or 1 for every pixel position depending on whether the value in the first or second image is the largest\n",
    "    binary_prediction = tf.math.argmax(logits, axis= 3, name= 'prediction')\n",
    "        \n",
    "    return binary_prediction, logits, output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXe-N1A0JgM5"
   },
   "outputs": [],
   "source": [
    "# define some different losses\n",
    "\n",
    "# loss defined as in the original UNet paper\n",
    "# The energy function is computed by a pixel-wise soft-max over the final feature map combined with the cross-entropy loss function\n",
    "def loss_UNet(predicted_logits, real_annotations):\n",
    "    # removes the last dimension of real_annotaitons (axis channel 1 has to be removed)\n",
    "    real_annotations = real_annotations[:,:,:,0]\n",
    "    \n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits (logits= predicted_logits, labels= real_annotations)\n",
    "    print(loss.shape)\n",
    "    loss = tf.reduce_mean(loss) \n",
    "    print(loss.shape)\n",
    "    \n",
    "    # extra L2- regularization can be added to the loss\n",
    "    # L2 = 0\n",
    "    # for p in tl.layers.get_variables_with_name('/W', True, True):\n",
    "    #   L2 += tf.contrib.layers.l2_regularizer(0.004)(p)\n",
    "    # cost = loss + L2\n",
    "    # print('Value of L2: {}'.format(L2))\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "# here it is the softmax focal cross entropy\n",
    "def loss_sfce(predicted_logits, real_annotations, alpha = 0.25, gamma = 2.0):\n",
    "    '''\n",
    "    This type of loss function tries to avoid data imbalance in image segmentation\n",
    "    There are two parameters alpha and gamma, the default values are indicated\n",
    "    gamma should always be greater than or equal to 0\n",
    "    '''\n",
    "\n",
    "    real_annotations = real_annotations[:,:,:,0]\n",
    "    pred_prob = tf.nn.softmax(predicted_logits)[:,:,:,1]\n",
    "    real_annotations = tf.cast(real_annotations, tf.float32)\n",
    "    \n",
    "    # classic binary cross_entropy is calculated\n",
    "    ce = K.binary_crossentropy(real_annotations, pred_prob, from_logits= False)\n",
    "\n",
    "    # binary cross-entropy is multiplied with two factors: alpha and modulating factor\n",
    "    # convert the logits predictions into probabilities\n",
    "    alpha_factor = 1.0\n",
    "    modulating_factor = 1.0\n",
    "    \n",
    "    if alpha:\n",
    "        alpha = tf.convert_to_tensor(alpha, dtype=K.floatx())\n",
    "        alpha_factor = real_annotations * alpha + (1 - real_annotations) * (1 - alpha)\n",
    "\n",
    "\n",
    "    p_t = (real_annotations * pred_prob) + ((1 - real_annotations) * (1 - pred_prob))\n",
    "    if gamma:\n",
    "        gamma = tf.convert_to_tensor(gamma, dtype=K.floatx())\n",
    "        modulating_factor = tf.pow((1.0 - p_t), gamma)\n",
    "\n",
    "    # compute the final loss and return\n",
    "    loss = alpha_factor * modulating_factor * ce\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Asymmetric similarity loss function, to balance recall and precision\n",
    "# the larger beta, the more important the recall becomes relative to the precision\n",
    "def loss_asl(predicted_logits, real_annotations, beta = 2):\n",
    "    real_annotations = real_annotations[:,:,:,0]\n",
    "    real_annotations = tf.cast(real_annotations, tf.float32)\n",
    "    pred_prob = tf.nn.softmax(predicted_logits)[:,:,:,1]\n",
    "    \n",
    "    prod_pos = pred_prob * real_annotations\n",
    "    sum_prod_pos = tf.reduce_sum(tf.reduce_sum(prod_pos, axis = 2), axis = 1)\n",
    "    prod_neg_pred = (1-pred_prob) * real_annotations\n",
    "    sum_prod_neg_pred = tf.reduce_sum(tf.reduce_sum(prod_neg_pred, axis = 2), axis = 1)\n",
    "    prod_neg_real = (pred_prob) * (1-real_annotations)\n",
    "    sum_prod_neg_real = tf.reduce_sum(tf.reduce_sum(prod_neg_real, axis = 2), axis = 1)\n",
    "\n",
    "    beta = tf.convert_to_tensor(beta, dtype=K.floatx())\n",
    "\n",
    "    num = (1+beta**2) * sum_prod_pos\n",
    "    denom = (1+beta**2) *sum_prod_pos + beta**2 * sum_prod_neg_pred + sum_prod_neg_real\n",
    "\n",
    "    loss = num/denom\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_Pr5rblUvBD"
   },
   "outputs": [],
   "source": [
    "# define some optimizers and apply them to the network\n",
    "def Adam_optimization(losses, lr = 0.001):\n",
    "    '''This function defines the Adam optimizer that will be used and applies it to optimize the weights during training'''\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "    train_variables_list = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(losses, var_list= train_variables_list)\n",
    "    train_optimization = optimizer.apply_gradients(gradients)\n",
    "            \n",
    "    return train_optimization\n",
    "\n",
    "def SGD_optimization(losses, lr = 0.001):\n",
    "    '''This function defines the Stochastic gradient descent optimizer that will be used and applies it to optimize the weights during trainin'''\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = lr)\n",
    "    train_variables_list = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(losses, var_list= train_variables_list)\n",
    "    train_optimization = optimizer.apply_gradients(gradients)\n",
    "\n",
    "    return train_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQg7qWs9Wo9r"
   },
   "outputs": [],
   "source": [
    "def train_network(TrainImages, TrainAnnotations, TestImages, TestAnnotations, \n",
    "                  Drop_Prob = 0.1, Init_Filters = 64, batch_size = 3, loss_function = 'UNet_loss', optim = 'Adam', \n",
    "                  learning_rate = tf.Variable(1e-5, dtype=tf.float32), MAX_EPOCH = 10, SaveResults = True, print_freq = 1):\n",
    "    '''\n",
    "    This function trains the UNet on the indicated train data with corresponding annotations\n",
    "    At the end the trained model is being saved\n",
    "    '''\n",
    "\n",
    "    # placeholders are created, variables to which data is assigned later on\n",
    "    print('Create placeholders')\n",
    "    image = tf.placeholder(tf.float32, [None,512,512, 3], name= 'image')\n",
    "    annotation = tf.placeholder(tf.int32, shape=[None, 512, 512, 1], name= \"annotation\")\n",
    "\n",
    "    # define the model that will be used for training and for testing\n",
    "    print('Define the model for training')\n",
    "    train_pred, train_logits, train_network = UNet(image, drop_prob = Drop_Prob, init_filters = Init_Filters, is_train = True)\n",
    "    print('Define the model for testing')\n",
    "    test_pred, test_logits, test_network = UNet(image, drop_prob = Drop_Prob, init_filters = Init_Filters, is_train = False)\n",
    "    \n",
    "    # define the output probability maps, losses and optimization for training and testing\n",
    "    print('Define outputs, losses and optimization')\n",
    "    # softmax activation creates a probability map which is the output\n",
    "    train_positive_prob = tf.nn.softmax(train_logits)[:, :, :, 1]\n",
    "    test_positive_prob = tf.nn.softmax(test_logits)[:, :, :, 1]\n",
    "    # loss function\n",
    "    if loss_function == 'UNet_loss':\n",
    "        train_loss_op = loss_UNet(train_logits, annotation)\n",
    "        test_loss_op= loss_UNet(test_logits, annotation)\n",
    "    elif loss_function == 'Sfce_loss':\n",
    "        train_loss_op = loss_sfce(train_logits, annotation, alpha = 0.25, gamma = 2.0)\n",
    "        test_loss_op= loss_sfce(test_logits, annotation, alpha = 0.25, gamma = 2.0)\n",
    "    elif loss_function == 'Asl_loss':\n",
    "        train_loss_op = loss_asl(train_logits, annotation)\n",
    "        test_loss_op= loss_asl(test_logits, annotation)\n",
    "    # optimization\n",
    "    if optim == 'Adam':\n",
    "        train_op = Adam_optimization(train_loss_op, learning_rate)\n",
    "    elif optim == 'sgd':\n",
    "        train_op = SGD_optimization(train_loss_op, learning_rate)\n",
    "        \n",
    "    # learning_rate decay at higher amounts of epochs \n",
    "    lr_assign_op = tf.assign(learning_rate, learning_rate / 10)\n",
    "    \n",
    "    # a session should be started in which all intermediate results are stored (also weights of the network for example)\n",
    "    sess = tf.Session()\n",
    "    # saving the train and test results and the trained model\n",
    "    if SaveResults:\n",
    "        # creating summary which stores the results that can be visualised with tensorboard\n",
    "        print(\"Setting up summary...\")\n",
    "        test_summary_op = tf.summary.merge_all()\n",
    "        # creating saver, used to save the trained model at the end\n",
    "        print(\"Setting up Saver...\")\n",
    "        saver = tf.train.Saver(max_to_keep=2)\n",
    "        summary_writer = tf.summary.FileWriter(log_dir_tens, sess.graph)\n",
    "\n",
    "        \n",
    "    tl.layers.initialize_global_variables(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # define the train and test batches that can be fed into the network\n",
    "    train_batch_data, test_batch_data = LoadBatchData(TrainImages, TrainAnnotations, TestImages, TestAnnotations)\n",
    "\n",
    "    # defining the numer of steps per epoch, based on the batchsize\n",
    "    train_nbr = TrainImages.shape[0]\n",
    "    test_nbr = TestImages.shape[0]\n",
    "    step_every_epoch = int(train_nbr/batch_size)\n",
    "    test_every_epoch = int(test_nbr/batch_size)\n",
    "    \n",
    "    # go over all epochs of training\n",
    "    for epo in range(1,MAX_EPOCH+1):\n",
    "        \n",
    "        # time is defined at the start of every epoch\n",
    "        start_time = time.time()\n",
    "        # resetting of all variables\n",
    "        train_loss, test_loss, train_aupr, test_aupr, train_auc, test_auc= 0, 0, 0, 0, 0, 0\n",
    "            \n",
    "        # go over all batches in one epoch\n",
    "        for s in range(step_every_epoch):\n",
    "        \n",
    "            # define the next batch to train the network\n",
    "            train_images_batch, train_annotations_batch = train_batch_data.next_batch(batch_size)\n",
    "            feed_dict = {image: train_images_batch, annotation: train_annotations_batch}\n",
    "            # train the network and define the output of the network for this batch of images\n",
    "            train_pos_prob, train_err, _ = sess.run([train_positive_prob, train_loss_op, train_op], feed_dict=feed_dict)\n",
    "\n",
    "            # auc and aupr score are calculated for this batch\n",
    "            temp_train_annotations = np.reshape(train_annotations_batch,-1)\n",
    "            temp_tra_positive_prob = np.reshape(train_pos_prob,-1)\n",
    "            train_sauc = ROC(temp_tra_positive_prob, temp_train_annotations, plot = False)\n",
    "            train_saupr = PRC(temp_tra_positive_prob, temp_train_annotations, plot = False)\n",
    "\n",
    "            # define the total loss, auc and aupr over all batches in 1 epoch\n",
    "            train_loss += train_err\n",
    "            train_auc += train_sauc\n",
    "            train_aupr += train_saupr\n",
    "            \n",
    "        # after every epoch, check whether results should be printed out and network should be tested\n",
    "        # print out after epoch 1 and then every print_freq\n",
    "        if epo % print_freq == 0 or epo == 1 or epo == (MAX_EPOCH):\n",
    "        \n",
    "            # average out loss, auc and aupr for the train set over all batches\n",
    "            train_loss = train_loss/step_every_epoch\n",
    "            train_auc = train_auc/step_every_epoch\n",
    "            train_aupr = train_aupr/step_every_epoch\n",
    "\n",
    "            # print out the training results\n",
    "            print('epoch {} took {}s'.format(epo, time.time() - start_time))\n",
    "            print('   train loss: {}'.format(train_loss))\n",
    "            print('   train auc: {}'.format(train_auc))\n",
    "            print('   train aupr: {}'.format(train_aupr))\n",
    "\n",
    "            if SaveResults:      \n",
    "                # save these values to visualize them later with tensorboard\n",
    "                train_summary = tf.Summary(value=[tf.Summary.Value(tag=\"train_loss\", simple_value=train_loss), tf.Summary.Value(tag=\"train_auc\", simple_value=train_auc),\n",
    "                                                tf.Summary.Value(tag=\"train_aupr\", simple_value=train_aupr)])\n",
    "                summary_writer.add_summary(train_summary, epo)\n",
    "                \n",
    "            # testing of the network\n",
    "            # test data is also subdivided in batches, go over all batches\n",
    "            for test_s in range(test_every_epoch):\n",
    "\n",
    "                # get the next batch of test data\n",
    "                test_images_batch, test_annotations_batch = test_batch_data.next_batch(batch_size)\n",
    "                # apply the network to the test images and define the output of the network and the loss\n",
    "                feed_dict= {image:test_images_batch, annotation:test_annotations_batch}\n",
    "                test_pos_prob, test_err = sess.run([test_positive_prob, test_loss_op], feed_dict= feed_dict)\n",
    "\n",
    "                # compute auc and aupr score for test set\n",
    "                temp_test_annotations = np.reshape(test_annotations_batch,-1)\n",
    "                temp_test_positive_prob = np.reshape(test_pos_prob,-1)\n",
    "                test_sauc = ROC(temp_test_positive_prob, temp_test_annotations, plot = False)\n",
    "                test_saupr= PRC(temp_test_positive_prob, temp_test_annotations, plot = False)\n",
    "\n",
    "                # calculate total loss, auc and aupr for the test set over all batches\n",
    "                test_loss += test_err\n",
    "                test_auc += test_sauc\n",
    "                test_aupr += test_saupr\n",
    "\n",
    "            # average loss, auc and aupr for the test set over all batches\n",
    "            test_loss = test_loss/test_every_epoch\n",
    "            test_auc = test_auc/test_every_epoch\n",
    "            test_aupr = test_aupr/test_every_epoch\n",
    "\n",
    "            # print out the test results\n",
    "            print('   test loss: {}'.format(test_loss))\n",
    "            print('   test auc: {}'.format(test_auc))\n",
    "            print('   test aupr: {}'.format(test_aupr))\n",
    "\n",
    "            if SaveResults:       \n",
    "                # save these values to visualize them later with tensorboard\n",
    "                test_summary = tf.Summary(value=[tf.Summary.Value(tag=\"test_loss\", simple_value=test_loss), tf.Summary.Value(tag=\"test_auc\", simple_value=test_auc), \n",
    "                                                tf.Summary.Value(tag=\"test_aupr\", simple_value=test_aupr)])\n",
    "                summary_writer.add_summary(test_summary, epo)\n",
    "\n",
    "                # tensorboard flush\n",
    "                summary_writer.flush() # the summary is written at this moment\n",
    "\n",
    "        # at specific amounts of epochs, the learning rate should become smaller to work more precisely\n",
    "        if epo == int(MAX_EPOCH*2/3) or epo == int(MAX_EPOCH/2): \n",
    "            sess.run(lr_assign_op)\n",
    "            \n",
    "        # eventual saving of the fully trained model\n",
    "        if SaveResults: \n",
    "            if epo == MAX_EPOCH:\n",
    "                saver.save(sess, log_dir_model + \"model.ckpt\", epo)\n",
    "                print('epoch {}, the model has been saved successfully'.format(epo))\n",
    "\n",
    "    return test_loss, test_auc, test_aupr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duNuxs-hltfr"
   },
   "outputs": [],
   "source": [
    "def ROC(pred_probs, true_probs, plot = True):\n",
    "    '''\n",
    "    This function calculates the ROC-AUC value\n",
    "    and it also calculates and visualizes the ROC-curve (if plot is true)\n",
    "    '''\n",
    "    \n",
    "    # calculate and print out ROC-AUC value\n",
    "    ROC_AUC = roc_auc_score(true_probs, pred_probs)\n",
    "    \n",
    "    # calculate and plot the ROC-curve\n",
    "    if plot:\n",
    "        FPRate, TPRate, Thresh = roc_curve(true_probs, pred_probs)\n",
    "        plt.figure()\n",
    "        plt.plot(FPRate, TPRate)\n",
    "        plt.title('ROC curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "    return ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5H_DmGBHltft"
   },
   "outputs": [],
   "source": [
    "def PRC(pred_probs, true_probs, plot = True):\n",
    "    '''\n",
    "    Calculate the aupr value = the area under the precision-recall curve\n",
    "    and plot the precision-recall curve (if plot is true)\n",
    "    '''\n",
    "    \n",
    "    # calculate the precision-recall curve\n",
    "    Precision, Recall, Thresh = precision_recall_curve(true_probs, pred_probs)\n",
    "    Precision = np.fliplr([Precision])[0]  # so the array is increasing (you won't get negative AUC)\n",
    "    Recall = np.fliplr([Recall])[0]  # so the array is increasing (you won't get negative AUC)\n",
    "    AUPR = np.trapz(Precision, Recall)\n",
    "      \n",
    "    \n",
    "    # plot the precision-recall curve\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(Precision, Recall)\n",
    "        plt.title('Precision-Recall curve')\n",
    "        plt.xlabel('Precision')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.show()\n",
    "    \n",
    "    return AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852851,
     "status": "ok",
     "timestamp": 1596615026199,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "00738778653758640454"
     },
     "user_tz": -120
    },
    "id": "AY41_1b53yRn",
    "outputId": "2efd1725-a792-4d9d-eea5-95052cebb37e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create placeholders\n",
      "Define the model for training\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/core.py:131: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "[TL] InputLayer  input: (?, 512, 512, 3)\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/convolution/simplified_conv.py:191: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py:104: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/pooling.py:200: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/pooling.py:311: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/dropout.py:100: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_3: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_4: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/image_resampling.py:78: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/image_resampling.py:80: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 2 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "Define the model for testing\n",
      "[TL] InputLayer  input: (?, 512, 512, 3)\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_3: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_4: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 2 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "Define outputs, losses and optimization\n",
      "(?, 512, 512)\n",
      "()\n",
      "(?, 512, 512)\n",
      "()\n",
      "Setting up summary...\n",
      "Setting up Saver...\n",
      "[TL] WARNING: Function: `tensorlayer.layers.utils.initialize_global_variables` (in file: /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py:213: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "Initializing Batch Dataset Reader...\n",
      "Shape images: (324, 512, 512, 3)\n",
      "Shape annotations: (324, 512, 512, 1)\n",
      "Initializing Batch Dataset Reader...\n",
      "Shape images: (156, 512, 512, 3)\n",
      "Shape annotations: (156, 512, 512, 1)\n",
      "epoch 1 took 306.5884974002838s\n",
      "   train loss: 0.36078445254652586\n",
      "   train auc: 0.4274469575259996\n",
      "   train aupr: 0.010282910564017244\n",
      "   test loss: 0.6930546107200476\n",
      "   test auc: 0.36828074277643175\n",
      "   test aupr: 0.012389727468089114\n",
      "epoch 2 took 288.3318564891815s\n",
      "   train loss: 0.08160155173391104\n",
      "   train auc: 0.4125833853688671\n",
      "   train aupr: 0.009158925979631834\n",
      "   test loss: 0.6930546141587771\n",
      "   test auc: 0.38419244452942897\n",
      "   test aupr: 0.012238212488500462\n",
      "epoch 2, the model has been saved successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6930546141587771, 0.38419244452942897, 0.012238212488500462)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_network(train_images, train_annotations, test_images, test_annotations, MAX_EPOCH = 2, loss_function = 'UNet_loss')\n",
    "# (TrainImages, TrainAnnotations, TestImages, TestAnnotations, \n",
    "#                   Drop_Prob = 0.1, Init_Filters = 64, batch_size = 3, loss_function = 'UNet_loss', optim = 'Adam', \n",
    "#                   learning_rate = tf.Variable(1e-3, dtype=tf.float32), MAX_EPOCH = 10, SaveResults = True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNet_Softmax_Training.ipynb",
   "provenance": [
    {
     "file_id": "1pvSj2cOo177dqWp1y6lbiwohGTGeGVm1",
     "timestamp": 1596124850987
    },
    {
     "file_id": "1ko8HCMMTNlaR1MCC-1f6QL1uAaqzHXwO",
     "timestamp": 1595928299309
    },
    {
     "file_id": "1cjKN36peUbhC36sgbu1cp5rwTPmzAtcg",
     "timestamp": 1595852695030
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
