{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ga1Mx266ltfH"
   },
   "source": [
    "This script is used to perform lesion segmentation in fundus photographs. The lesions that can be segmented are hard exudates, soft exudates, microaneurysms and hemorrhages. The segmentation is based on a UNet, a CNN that takes an image as an input and that outputs a probability map indicating for every pixel the probability of belonging to a certain type of lesion or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6031,
     "status": "ok",
     "timestamp": 1596373774482,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "Gf8WnH-elznb",
    "outputId": "cd28f438-af06-4f6e-e8f6-91227b118f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorlayer==1.11.1 in /usr/local/lib/python3.6/dist-packages (1.11.1)\n",
      "Requirement already satisfied: scikit-image<0.15,>=0.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (0.14.5)\n",
      "Requirement already satisfied: tqdm<4.29,>=4.23 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (4.28.1)\n",
      "Requirement already satisfied: numpy<1.16,>=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.15.4)\n",
      "Requirement already satisfied: matplotlib<3.1,>=2.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (3.0.3)\n",
      "Requirement already satisfied: scipy<1.2,>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.1.0)\n",
      "Requirement already satisfied: wrapt<1.11,>=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.10.11)\n",
      "Requirement already satisfied: lxml<4.3,>=4.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (4.2.6)\n",
      "Requirement already satisfied: progressbar2<3.39,>=3.38 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (3.38.0)\n",
      "Requirement already satisfied: requests<2.21,>=2.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (2.20.1)\n",
      "Requirement already satisfied: scikit-learn<0.21,>=0.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (0.20.4)\n",
      "Requirement already satisfied: imageio<2.5,>=2.3 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (2.4.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (7.0.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (1.3.0)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (2.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (1.15.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (2.4.7)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2<3.39,>=3.38->tensorlayer==1.11.1) (2.4.0)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (3.0.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorlayer==1.11.1\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7184,
     "status": "ok",
     "timestamp": 1596373779303,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "9eyAksxJOFsi",
    "outputId": "c963187a-40ac-4b40-e4f3-6286e085876b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/core.py:39: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/pooling.py:66: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import tensorlayer.layers as tll\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4SbTTqBltfN"
   },
   "outputs": [],
   "source": [
    "# read in the train and test data\n",
    "\n",
    "# Basepath depends on the lesion\n",
    "# LesionType = 'SoftExudates'\n",
    "LesionType = 'HardExudates'\n",
    "# LesionType = 'Microaneurysms'\n",
    "# LesionType = 'Hemorrhages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4427,
     "status": "ok",
     "timestamp": 1596373779305,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "k4EhTCYpm00v",
    "outputId": "44eaafad-6c74-4fce-bd01-857c9094ed06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# read in train and test data in case Google DRIVE is used\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 90597,
     "status": "ok",
     "timestamp": 1596373867080,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "fWfUoeuDltfV",
    "outputId": "2ab5bb1c-ea44-4774-ef26-e3d050174d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train images: (324, 512, 512, 3)\n",
      "Shape train annotations: (324, 512, 512)\n",
      "Shape test images: (156, 512, 512, 3)\n",
      "Shape test annotations: (156, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# basepath for google drive\n",
    "# Basepath = '/content/drive/My Drive/Stage_ENT_Studios/Data/IDRiD/' + LesionType + '/Arrays/'\n",
    "\n",
    "# basepath for jupyter notebooks\n",
    "Basepath = 'C:/Users/lunam/Documents/1steMaster/Stage/Data_FinalArrays/IDRiD/'+ LesionType+'/Arrays/'\n",
    "\n",
    "\n",
    "# train data\n",
    "train_images = np.float32(np.load(Basepath + 'train_images_Final.npy'))\n",
    "print('Shape train images: {}'.format(train_images.shape))\n",
    "\n",
    "train_annotations =  np.int32(np.load(Basepath + 'train_annotations_Final.npy'))\n",
    "# train_annotations = np.expand_dims(train_annotations, axis = 3)\n",
    "print('Shape train annotations: {}'.format(train_annotations.shape))\n",
    "\n",
    "# test data\n",
    "test_images = np.float32(np.load(Basepath + 'test_images_Final.npy'))\n",
    "print('Shape test images: {}'.format(test_images.shape))\n",
    "\n",
    "test_annotations = np.int32(np.load(Basepath + 'test_annotations_Final.npy'))\n",
    "# test_annotations = np.expand_dims(test_annotations, axis = 3)\n",
    "print('Shape test annotations: {}'.format(test_annotations.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVa4yn4lltfc"
   },
   "outputs": [],
   "source": [
    "# Load the tensorboard extension. Tensorboard will be used to visualize the training and testing of the network\n",
    "%load_ext tensorboard\n",
    "\n",
    "# basepath google drive\n",
    "# base_path = '/content/drive/My Drive/Stage_ENT_Studios/Unet/Logs/'\n",
    "\n",
    "# basepath jupyter notebooks\n",
    "base_path = 'C:/Users/lunam/Documents/1steMaster/Stage/Code_Final/DR_classification/FeatureBasedClassification/UNet_Softmax/Logs/'+LesionType+'/'\n",
    "\n",
    "\n",
    "# direction where the tensorboard files will be stored\n",
    "log_dir_tens = base_path + 'Tensorboard_Logs/'\n",
    "# direction where the trained models will be stored\n",
    "log_dir_model = base_path + 'Trained_Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05Xofm8P4hR9"
   },
   "outputs": [],
   "source": [
    "class BatchData():\n",
    "    '''\n",
    "    This class is used to create batches of images with their corresponding annotations\n",
    "    These batches can then be fed to the Unet\n",
    "    The numpy arrays of preprocessed images and corresponding annotations are given as an input to the class\n",
    "    '''\n",
    "    \n",
    "    # resetting all values in case a new batch dataset is created\n",
    "    images = []\n",
    "    annotations = []\n",
    "    batch_offset = 0\n",
    "    epochs_completed = 0 \n",
    "\n",
    "\n",
    "    def __init__(self, image_arrays, annotation_arrays):\n",
    "        \n",
    "        print(\"Initializing Batch Dataset Reader...\")\n",
    "        \n",
    "        self.images = image_arrays\n",
    "        self.annotations = annotation_arrays\n",
    "\n",
    "        # resize the annotations to indicate that there is only one channel in this case\n",
    "        self.annotations = np.expand_dims(self.annotations, 3)\n",
    "        # this makes a binary mask of the annotations, there where annotations has a pixel value above 0, the pixel value will be set to 1\n",
    "        # there where the pixel value is 0 or smaller, the pixel value is set to 0\n",
    "        self.annotations = np.where(self.annotations>0, 1, 0)\n",
    "        \n",
    "        print ('Shape images: {}'.format(self.images.shape))\n",
    "        print ('Shape annotations: {}'.format(self.annotations.shape))\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        '''\n",
    "        This function can be used to everytime find the next batch of images and corresponding annotations\n",
    "        The size of the batches is defined by the batch_size\n",
    "        '''\n",
    "        \n",
    "        # start image of the batch\n",
    "        start = self.batch_offset\n",
    "        # set the starting value for the next batch\n",
    "        self.batch_offset += batch_size \n",
    "        \n",
    "        # all data has already been used\n",
    "        if self.batch_offset > self.images.shape[0]:\n",
    "            \n",
    "            # images and annotations get shuffled randomly for the next epoch\n",
    "            perm = np.arange(self.images.shape[0])\n",
    "            np.random.shuffle(perm)\n",
    "            self.images = self.images[perm]\n",
    "            self.annotations = self.annotations[perm]\n",
    "            \n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self.batch_offset = batch_size\n",
    "        \n",
    "        # end image of the batch\n",
    "        end = self.batch_offset\n",
    "        \n",
    "        # return the images and corresponding annotations in this batch\n",
    "        return self.images[start:end], self.annotations[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55GrGQj34IK8"
   },
   "outputs": [],
   "source": [
    "def LoadBatchData(Train_Images, Train_Annotations, Test_Images, Test_Annotations):\n",
    "    '''\n",
    "    This function creates a batch dataset for the train and test set\n",
    "    '''\n",
    "    \n",
    "    # create a batchdataset for the train set\n",
    "    train_batch_data = BatchData(Train_Images, Train_Annotations)\n",
    "            \n",
    "    # create a batchdataset for the test set\n",
    "    test_batch_data = BatchData(Test_Images, Test_Annotations)\n",
    "            \n",
    "    # return the train and test batch dataset\n",
    "    return train_batch_data, test_batch_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FICWJHVxltfh"
   },
   "outputs": [],
   "source": [
    "# The UNet network\n",
    "def UNet(image, drop_prob = 0.1, init_filters = 64, reuse = False, is_train = True):\n",
    "    '''This function defines the original UNet network'''\n",
    "    \n",
    "    # initialization of the weights\n",
    "    W_init = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "    # Unet network\n",
    "                \n",
    "    # LEFT part\n",
    "    # input layer\n",
    "    input_image = tl.layers.InputLayer(image)\n",
    "            \n",
    "    # Convolutional block 1\n",
    "    conv2d_1 = tl.layers.Conv2d(input_image, init_filters, (3, 3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_2 = tl.layers.Conv2d(conv2d_1, init_filters, (3, 3), act= tf.nn.relu, W_init= W_init)\n",
    "    pool_1 = tl.layers.MaxPool2d(conv2d_2, (2, 2), (2, 2), name= 'maxpool_1')\n",
    "    dropout_1 = tl.layers.DropoutLayer(pool_1, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 2\n",
    "    conv2d_3 = tl.layers.Conv2d(dropout_1, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_4 = tl.layers.Conv2d(conv2d_3, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    pool_2 = tl.layers.MaxPool2d(conv2d_4, (2,2), (2, 2), name='maxpool_2')\n",
    "    dropout_2 = tl.layers.DropoutLayer(pool_2, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 3\n",
    "    conv2d_5 = tl.layers.Conv2d(dropout_2, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_6 = tl.layers.Conv2d(conv2d_5, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    pool_3 = tl.layers.MaxPool2d(conv2d_6, (2,2), (2, 2), name='maxpool_3')\n",
    "    dropout_3 = tl.layers.DropoutLayer(pool_3, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 4\n",
    "    conv2d_7 = tl.layers.Conv2d(dropout_3, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_8 = tl.layers.Conv2d(conv2d_7, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    pool_4 = tl.layers.MaxPool2d(conv2d_8, (2,2), (2, 2), name='maxpool_4')\n",
    "    dropout_4 = tl.layers.DropoutLayer(pool_4, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # MIDDLE part\n",
    "    conv2d_9 = tl.layers.Conv2d(dropout_4, 16*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_10 = tl.layers.Conv2d(conv2d_9, 16*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "                \n",
    "                \n",
    "    # RIGHT part\n",
    "    # Convolutional block 1\n",
    "    upsampling_1 = tl.layers.UpSampling2dLayer(conv2d_10, (2,2))\n",
    "    concat_1 = tl.layers.ConcatLayer([upsampling_1, conv2d_8], 3)\n",
    "    dropout_5 = tl.layers.DropoutLayer(concat_1, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_11 = tl.layers.Conv2d(dropout_5, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_12 = tl.layers.Conv2d(conv2d_11, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "                \n",
    "    # Convolutional block 2\n",
    "    upsampling_2 = tl.layers.UpSampling2dLayer(conv2d_12, (2,2))\n",
    "    concat_2 = tl.layers.ConcatLayer([upsampling_2, conv2d_6], 3)\n",
    "    dropout_6 = tl.layers.DropoutLayer(concat_2, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_13 = tl.layers.Conv2d(dropout_6, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_14 = tl.layers.Conv2d(conv2d_13, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "            \n",
    "                \n",
    "    # Convolutional block 3\n",
    "    upsampling_3 = tl.layers.UpSampling2dLayer(conv2d_14, (2,2))\n",
    "    concat_3 = tl.layers.ConcatLayer([upsampling_3,conv2d_4], 3)\n",
    "    dropout_7 = tl.layers.DropoutLayer(concat_3, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_15 = tl.layers.Conv2d(dropout_7, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_16 = tl.layers.Conv2d(conv2d_15, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "                \n",
    "    # Convolutional block 4\n",
    "    upsampling_4 = tl.layers.UpSampling2dLayer(conv2d_16, (2,2))\n",
    "    concat_4 = tl.layers.ConcatLayer([upsampling_4,conv2d_2], 3)\n",
    "    dropout_8 = tl.layers.DropoutLayer(concat_4, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_17 = tl.layers.Conv2d(dropout_8, init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_18 = tl.layers.Conv2d(conv2d_17, init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "                \n",
    "                \n",
    "    # ouput layer\n",
    "    output_image = tl.layers.Conv2d(conv2d_18, 2, (1,1), W_init= W_init) \n",
    "\n",
    "    # logits tensor, often a step inbetween befor a softmax activation is applied (size im_size x im_size, 2)\n",
    "    logits = output_image.outputs\n",
    "\n",
    "    # the model\n",
    "    model = output_image\n",
    "\n",
    "    # a binary output map with size im_size x im_size can be found by applying the argmax operation\n",
    "    # this operation yields 0 or 1 for every pixel position depending on whether the value in the first or second image is the largest\n",
    "    binary_prediction = tf.math.argmax(logits, axis= 3, name= 'prediction')\n",
    "        \n",
    "    return binary_prediction, logits, output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8--2z25Tzprv"
   },
   "source": [
    "The sigmoid focal cross-entropy is implemented making use of the source code: \n",
    "https://github.com/tensorflow/addons/blob/v0.10.0/tensorflow_addons/losses/focal_loss.py#L26-L85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXe-N1A0JgM5"
   },
   "outputs": [],
   "source": [
    "# define some different losses\n",
    "\n",
    "# loss defined as in the original UNet paper\n",
    "# The energy function is computed by a pixel-wise soft-max over the final feature map combined with the cross-entropy loss function\n",
    "def loss_UNet(predicted_logits, real_annotations):\n",
    "    # removes the last dimension of real_annotaitons (axis channel 1 has to be removed)\n",
    "    real_annotations = real_annotations[:,:,:,0]\n",
    "    \n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits (logits= predicted_logits, labels= real_annotations)\n",
    "    print(loss.shape)\n",
    "    loss = tf.reduce_mean(loss) \n",
    "    print(loss.shape)\n",
    "    \n",
    "    # extra L2- regularization can be added to the loss\n",
    "    # L2 = 0\n",
    "    # for p in tl.layers.get_variables_with_name('/W', True, True):\n",
    "    #   L2 += tf.contrib.layers.l2_regularizer(0.004)(p)\n",
    "    # cost = loss + L2\n",
    "    # print('Value of L2: {}'.format(L2))\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "# here it is the softmax focal cross entropy\n",
    "def loss_sfce(predicted_logits, real_annotations, alpha = 0.25, gamma = 2.0):\n",
    "    '''\n",
    "    This type of loss function tries to avoid data imbalance in image segmentation\n",
    "    There are two parameters alpha and gamma, the default values are indicated\n",
    "    gamma should always be greater than or equal to 0\n",
    "    '''\n",
    "\n",
    "    real_annotations = real_annotations[:,:,:,0]\n",
    "    pred_prob = tf.nn.softmax(predicted_logits)[:,:,:,1]\n",
    "    real_annotations = tf.cast(real_annotations, tf.float32)\n",
    "    \n",
    "    # classic binary cross_entropy is calculated\n",
    "    ce = K.binary_crossentropy(real_annotations, pred_prob, from_logits= False)\n",
    "\n",
    "    # binary cross-entropy is multiplied with two factors: alpha and modulating factor\n",
    "    # convert the logits predictions into probabilities\n",
    "    alpha_factor = 1.0\n",
    "    modulating_factor = 1.0\n",
    "    \n",
    "    if alpha:\n",
    "        alpha = tf.convert_to_tensor(alpha, dtype=K.floatx())\n",
    "        alpha_factor = real_annotations * alpha + (1 - real_annotations) * (1 - alpha)\n",
    "\n",
    "\n",
    "    p_t = (real_annotations * pred_prob) + ((1 - real_annotations) * (1 - pred_prob))\n",
    "    if gamma:\n",
    "        gamma = tf.convert_to_tensor(gamma, dtype=K.floatx())\n",
    "        modulating_factor = tf.pow((1.0 - p_t), gamma)\n",
    "\n",
    "    # compute the final loss and return\n",
    "    loss = alpha_factor * modulating_factor * ce\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Asymmetric similarity loss function, to balance recall and precision\n",
    "# the larger beta, the more important the recall becomes relative to the precision\n",
    "def loss_asl(predicted_logits, real_annotations, beta = 1):\n",
    "    real_annotations = real_annotations[:,:,:,0]\n",
    "    real_annotations = tf.cast(real_annotations, tf.float32)\n",
    "    pred_prob = tf.nn.softmax(predicted_logits)[:,:,:,1]\n",
    "    \n",
    "    prod_pos = pred_prob * real_annotations\n",
    "    sum_prod_pos = tf.reduce_sum(tf.reduce_sum(prod_pos, axis = 2), axis = 1)\n",
    "    prod_neg_pred = (1-pred_prob) * real_annotations\n",
    "    sum_prod_neg_pred = tf.reduce_sum(tf.reduce_sum(prod_neg_pred, axis = 2), axis = 1)\n",
    "    prod_neg_real = (pred_prob) * (1-real_annotations)\n",
    "    sum_prod_neg_real = tf.reduce_sum(tf.reduce_sum(prod_neg_real, axis = 2), axis = 1)\n",
    "\n",
    "    beta = tf.convert_to_tensor(beta, dtype=K.floatx())\n",
    "\n",
    "    num = (1+beta**2) * sum_prod_pos\n",
    "    denom = (1+beta**2) *sum_prod_pos + beta**2 * sum_prod_neg_pred + sum_prod_neg_real\n",
    "\n",
    "    loss = num/denom\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_Pr5rblUvBD"
   },
   "outputs": [],
   "source": [
    "# define some optimizers and apply them to the network\n",
    "def Adam_optimization(losses, lr = 0.001):\n",
    "    '''This function defines the Adam optimizer that will be used and applies it to optimize the weights during training'''\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "    train_variables_list = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(losses, var_list= train_variables_list)\n",
    "    train_optimization = optimizer.apply_gradients(gradients)\n",
    "            \n",
    "    return train_optimization\n",
    "\n",
    "def SGD_optimization(losses, lr = 0.001):\n",
    "    '''This function defines the Stochastic gradient descent optimizer that will be used and applies it to optimize the weights during trainin'''\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = lr)\n",
    "    train_variables_list = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(losses, var_list= train_variables_list)\n",
    "    train_optimization = optimizer.apply_gradients(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pu2BisSvWxKr"
   },
   "outputs": [],
   "source": [
    "# some training constants\n",
    "\n",
    "print_freq = 1 # print frequency indicates how often results are printed out (amount of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ay2CXe5mXSFd"
   },
   "outputs": [],
   "source": [
    "# # flags parameters, indicating in what mode the system is: training or testing and visualizing\n",
    "# FLAGS = tf.flags.FLAGS\n",
    "# tf.flags.DEFINE_string('mode', \"train\", \"Mode train/ test/ visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQg7qWs9Wo9r"
   },
   "outputs": [],
   "source": [
    "def train_network(TrainImages, TrainAnnotations, TestImages, TestAnnotations, \n",
    "                  Drop_Prob = 0.1, Init_Filters = 64, batch_size = 3, loss_function = 'UNet_loss', optim = 'Adam', \n",
    "                  learning_rate = tf.Variable(1e-5, dtype=tf.float32), MAX_EPOCH = 10, SaveResults = True):\n",
    "    '''\n",
    "    This function trains the UNet on the indicated train data with corresponding annotations\n",
    "    At the end the trained model is being saved\n",
    "    '''\n",
    "\n",
    "    # placeholders are created, variables to which data is assigned later on\n",
    "    print('Create placeholders')\n",
    "    image = tf.placeholder(tf.float32, [None,512,512, 3], name= 'image')\n",
    "    annotation = tf.placeholder(tf.int32, shape=[None, 512, 512, 1], name= \"annotation\")\n",
    "\n",
    "    # define the model that will be used for training and for testing\n",
    "    print('Define the model for training')\n",
    "    train_pred, train_logits, train_network = UNet(image, drop_prob = Drop_Prob, init_filters = Init_Filters, reuse = False, is_train = True)\n",
    "    print('Define the model for testing')\n",
    "    test_pred, test_logits, test_network = UNet(image, drop_prob = Drop_Prob, init_filters = Init_Filters, reuse = True, is_train = False)\n",
    "    \n",
    "    # define the output probability maps, losses and optimization for training and testing\n",
    "    print('Define outputs, losses and optimization')\n",
    "    # softmax activation creates a probability map which is the output\n",
    "    train_positive_prob = tf.nn.softmax(train_logits)[:, :, :, 1]\n",
    "    test_positive_prob = tf.nn.softmax(test_logits)[:, :, :, 1]\n",
    "    # loss function\n",
    "    if loss_function == 'UNet_loss':\n",
    "        train_loss_op = loss_UNet(train_logits, annotation)\n",
    "        test_loss_op= loss_UNet(test_logits, annotation)\n",
    "    elif loss_function == 'Sfce_loss':\n",
    "        train_loss_op = loss_sfce(train_logits, annotation, alpha = 0.25, gamma = 2.0)\n",
    "        test_loss_op= loss_sfce(test_logits, annotation, alpha = 0.25, gamma = 2.0)\n",
    "    elif loss_function == 'Asl_loss':\n",
    "        train_loss_op = loss_asl(train_logits, annotation)\n",
    "        test_loss_op= loss_asl(test_logits, annotation)\n",
    "    # optimization\n",
    "    if optim == 'Adam':\n",
    "        train_op = Adam_optimization(train_loss_op, learning_rate)\n",
    "    elif optim == 'sgd':\n",
    "        train_op = SGD_optimization(train_loss_op, learning_rate)\n",
    "        \n",
    "    # learning_rate decay at higher amounts of epochs \n",
    "    lr_assign_op = tf.assign(learning_rate, learning_rate / 10)\n",
    "    \n",
    "    # a session should be started in which all intermediate results are stored (also weights of the network for example)\n",
    "    sess = tf.Session()\n",
    "    # saving the train and test results and the trained model\n",
    "    if SaveResults:\n",
    "        # creating summary which stores the results that can be visualised with tensorboard\n",
    "        print(\"Setting up summary...\")\n",
    "        # test_summary_op = tf.summary.merge_all()\n",
    "        # creating saver, used to save the trained model at the end\n",
    "        print(\"Setting up Saver...\")\n",
    "        saver = tf.train.Saver(max_to_keep=2)\n",
    "        summary_writer = tf.summary.FileWriter(log_dir_tens, sess.graph)\n",
    "\n",
    "        \n",
    "    tl.layers.initialize_global_variables(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # define the train and test batches that can be fed into the network\n",
    "    train_batch_data, test_batch_data = LoadBatchData(TrainImages, TrainAnnotations, TestImages, TestAnnotations)\n",
    "\n",
    "    # defining the numer of steps per epoch, based on the batchsize\n",
    "    train_nbr = TrainImages.shape[0]\n",
    "    test_nbr = TestImages.shape[0]\n",
    "    step_every_epoch = int(train_nbr/batch_size)\n",
    "    test_every_epoch = int(test_nbr/batch_size)\n",
    "    \n",
    "    # go over all epochs of training\n",
    "    for epo in range(1,MAX_EPOCH+1):\n",
    "        \n",
    "        # time is defined at the start of every epoch\n",
    "        start_time = time.time()\n",
    "        # resetting of all variables\n",
    "        train_loss, test_loss, train_aupr, test_aupr, train_auc, test_auc= 0, 0, 0, 0, 0, 0\n",
    "            \n",
    "        # go over all batches in one epoch\n",
    "        for s in range(step_every_epoch):\n",
    "        \n",
    "            # define the next batch to train the network\n",
    "            train_images_batch, train_annotations_batch = train_batch_data.next_batch(batch_size)\n",
    "            feed_dict = {image: train_images_batch, annotation: train_annotations_batch}\n",
    "            # train the network and define the output of the network for this batch of images\n",
    "            train_pos_prob, train_err, _ = sess.run([train_positive_prob, train_loss_op, train_op], feed_dict=feed_dict)\n",
    "\n",
    "            # auc and aupr score are calculated for this batch\n",
    "            temp_train_annotations = np.reshape(train_annotations_batch,-1)\n",
    "            temp_tra_positive_prob = np.reshape(train_pos_prob,-1)\n",
    "            train_sauc = ROC(temp_tra_positive_prob, temp_train_annotations, plot = False)\n",
    "            train_saupr = PRC(temp_tra_positive_prob, temp_train_annotations, plot = False)\n",
    "\n",
    "            # define the total loss, auc and aupr over all batches in 1 epoch\n",
    "            train_loss += train_err\n",
    "            train_auc += train_sauc\n",
    "            train_aupr += train_saupr\n",
    "            \n",
    "        # after every epoch, check whether results should be printed out and network should be tested\n",
    "        # print out after epoch 1 and then every print_freq\n",
    "        if epo % print_freq == 0 or epo == 1 or epo == (MAX_EPOCH):\n",
    "        \n",
    "            # average out loss, auc and aupr for the train set over all batches\n",
    "            train_loss = train_loss/step_every_epoch\n",
    "            train_auc = train_auc/step_every_epoch\n",
    "            train_aupr = train_aupr/step_every_epoch\n",
    "\n",
    "            # print out the training results\n",
    "            print('epoch {} took {}s'.format(epo, time.time() - start_time))\n",
    "            print('   train loss: {}'.format(train_loss))\n",
    "            print('   train auc: {}'.format(train_auc))\n",
    "            print('   train aupr: {}'.format(train_aupr))\n",
    "\n",
    "            if SaveResults:      \n",
    "                # save these values to visualize them later with tensorboard\n",
    "                train_summary = tf.Summary(value=[tf.Summary.Value(tag=\"train_loss\", simple_value=train_loss), tf.Summary.Value(tag=\"train_auc\", simple_value=train_auc),\n",
    "                                                tf.Summary.Value(tag=\"train_aupr\", simple_value=train_aupr)])\n",
    "                summary_writer.add_summary(train_summary, epo)\n",
    "\n",
    "            # testing of the network\n",
    "            # test data is also subdivided in batches, go over all batches\n",
    "            for test_s in range(test_every_epoch):\n",
    "\n",
    "                # get the next batch of test data\n",
    "                test_images_batch, test_annotations_batch = test_batch_data.next_batch(batch_size)\n",
    "                # apply the network to the test images and define the output of the network and the loss\n",
    "                feed_dict= {image:test_images_batch, annotation:test_annotations_batch}\n",
    "                test_pos_prob, test_err = sess.run([test_positive_prob, test_loss_op], feed_dict= feed_dict)\n",
    "\n",
    "                # compute auc and aupr score for test set\n",
    "                temp_test_annotations = np.reshape(test_annotations_batch,-1)\n",
    "                temp_test_positive_prob = np.reshape(test_pos_prob,-1)\n",
    "                test_sauc = ROC(temp_test_positive_prob, temp_test_annotations, plot = False)\n",
    "                test_saupr= PRC(temp_test_positive_prob, temp_test_annotations, plot = False)\n",
    "\n",
    "                # calculate total loss, auc and aupr for the test set over all batches\n",
    "                test_loss += test_err\n",
    "                test_auc += test_sauc\n",
    "                test_aupr += test_saupr\n",
    "\n",
    "            # average loss, auc and aupr for the test set over all batches\n",
    "            test_loss = test_loss/test_every_epoch\n",
    "            test_auc = test_auc/test_every_epoch\n",
    "            test_aupr = test_aupr/test_every_epoch\n",
    "\n",
    "            # print out the test results\n",
    "            print('   test loss: {}'.format(test_loss))\n",
    "            print('   test auc: {}'.format(test_auc))\n",
    "            print('   test aupr: {}'.format(test_aupr))\n",
    "\n",
    "            if SaveResults:       \n",
    "                # save these values to visualize them later with tensorboard\n",
    "                # print('1')\n",
    "                test_summary = tf.Summary(value=[tf.Summary.Value(tag=\"test_loss\", simple_value=test_loss), tf.Summary.Value(tag=\"test_auc\", simple_value=test_auc), \n",
    "                                                tf.Summary.Value(tag=\"test_aupr\", simple_value=test_aupr)])\n",
    "                # print('2')\n",
    "                summary_writer.add_summary(test_summary, epo)\n",
    "\n",
    "                # # visualize the test result(only visualize the last batchsize of this epoch)\n",
    "                # print('3')\n",
    "                # feed_dict= {image:test_images_batch, annotation:test_annotations_batch}\n",
    "                # print('4')\n",
    "                # print(type(test_summary_op))\n",
    "                # summary_str = sess.run(test_summary_op, feed_dict = feed_dict)\n",
    "                # print('5')\n",
    "                # summary_writer.add_summary(summary_str, epo)\n",
    "                # print('6')   \n",
    "\n",
    "                # tensorboard flush\n",
    "                summary_writer.flush() # the summary is written at this moment\n",
    "                # sys.stdout.flush()\n",
    "            \n",
    "        # at specific amounts of epochs, the learning rate should become smaller to work more precisely\n",
    "        if epo == int(MAX_EPOCH*2/3) or epo == int(MAX_EPOCH/2): \n",
    "            sess.run(lr_assign_op)\n",
    "            \n",
    "        # eventual saving of the fully trained model\n",
    "        if SaveResults: \n",
    "            if epo % (MAX_EPOCH) == 0:\n",
    "                saver.save(sess, log_dir_model + \"model.ckpt\", epo)\n",
    "                print('epoch {}, the model has been saved successfully'.format(epo))\n",
    "                # force the system to write now\n",
    "                # sys.stdout.flush()\n",
    "\n",
    "    return test_loss, test_auc, test_aupr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 361261,
     "status": "error",
     "timestamp": 1596374160944,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "5DMNAkR18IxP",
    "outputId": "6b0fa7b1-e3e1-46b3-8e06-5fcf38705718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create placeholders\n",
      "Define the model for training\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/core.py:131: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "[TL] InputLayer  input: (?, 512, 512, 3)\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/convolution/simplified_conv.py:191: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py:104: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/pooling.py:200: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/pooling.py:311: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/dropout.py:100: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_3: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_4: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/image_resampling.py:78: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/image_resampling.py:80: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 2 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "Define the model for testing\n",
      "[TL] InputLayer  input: (?, 512, 512, 3)\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_3: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_4: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 2 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "Define outputs, losses and optimization\n",
      "(?, 512, 512)\n",
      "()\n",
      "(?, 512, 512)\n",
      "()\n",
      "Setting up summary...\n",
      "Setting up Saver...\n",
      "[TL] WARNING: Function: `tensorlayer.layers.utils.initialize_global_variables` (in file: /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py:213: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "Initializing Batch Dataset Reader...\n",
      "Shape images: (324, 512, 512, 3)\n",
      "Shape annotations: (324, 512, 512, 1)\n",
      "Initializing Batch Dataset Reader...\n",
      "Shape images: (156, 512, 512, 3)\n",
      "Shape annotations: (156, 512, 512, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cfed58111a26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'UNet_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# TrainImages, TrainAnnotations, TestImages, TestAnnotations,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#                   Drop_Prob = 0.1, Init_Filters = 64, batch_size = 3, loss_function = 'UNet_loss', optim = 'Adam',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                   learning_rate = tf.Variable(1e-3, dtype=tf.float32), MAX_EPOCH = 10, SaveResults = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-00d1ea69fa46>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(TrainImages, TrainAnnotations, TestImages, TestAnnotations, Drop_Prob, Init_Filters, batch_size, loss_function, optim, learning_rate, MAX_EPOCH, SaveResults)\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_images_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_annotations_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0;31m# train the network and define the output of the network for this batch of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mtrain_pos_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_positive_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0;31m# auc and aupr score are calculated for this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network(train_images, train_annotations, test_images, test_annotations, MAX_EPOCH = 10, loss_function = 'UNet_loss')\n",
    "# TrainImages, TrainAnnotations, TestImages, TestAnnotations, \n",
    "#                   Drop_Prob = 0.1, Init_Filters = 64, batch_size = 3, loss_function = 'UNet_loss', optim = 'Adam', \n",
    "#                   learning_rate = tf.Variable(1e-3, dtype=tf.float32), MAX_EPOCH = 10, SaveResults = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjfEDsqrkurF"
   },
   "outputs": [],
   "source": [
    "# visualize the training results with tensorboard\n",
    "%tensorboard --logdir {log_dir_tens}  --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDik2rGzs3j4"
   },
   "outputs": [],
   "source": [
    "def Reload_and_Predict(TestImages, TestAnnotations, Drop_Prob = 0.1, Init_Filters = 64, log_dir_trained_model = log_dir_model, test_batch = 6):\n",
    "    '''This function reloads a trained model and predicts the annotations of images'''\n",
    "    TestAnnotations = np.expand_dims(TestAnnotations, axis = 3)\n",
    "    TestAnnotations = np.where(TestAnnotations> 0, 1, 0)\n",
    "    \n",
    "    # placeholders are created, variables to which data is assigned later on\n",
    "    print('Create placeholders')\n",
    "    image = tf.placeholder(tf.float32, [None,512,512, 3], name= 'image')\n",
    "    annotation = tf.placeholder(tf.int32, shape=[None, 512, 512, 1], name= \"annotation\")\n",
    "\n",
    "    # Define the model for testing\n",
    "    print('Define the model for testing')\n",
    "    test_pred, test_logits, test_network = UNet(image, drop_prob = Drop_Prob, init_filters = Init_Filters, reuse = True, is_train = False)\n",
    "        \n",
    "    # softmax activation of the output to end up with probability maps\n",
    "    print('Define the probability outputs')\n",
    "    test_positive_prob = tf.nn.softmax(test_logits)[:, :, :, 1]\n",
    "        \n",
    "    # start up a session in which the pretrained model is reloaded\n",
    "    sess = tf.Session()    \n",
    "    tl.layers.initialize_global_variables(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('Restoring model...')\n",
    "    new_saver = tf.train.import_meta_graph(log_dir_trained_model + 'model.ckpt-10.meta')\n",
    "    ckpt = tf.train.get_checkpoint_state(log_dir_trained_model)\n",
    "    new_saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print('Model restored...')\n",
    "        \n",
    "    # predict the annotations for the test images\n",
    "    print('Predicting the test cases...')\n",
    "\n",
    "    # the test samples have to go through in batches as otherwise the memmory crashes\n",
    "    # number of batches\n",
    "    predicted_prob_maps = []\n",
    "    n_batches = int(TestImages.shape[0] / test_batch)\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        start = i*test_batch\n",
    "        end = start + test_batch\n",
    "        feed_dict= {image: TestImages[start:end]}\n",
    "        test_pos_prob= sess.run([test_positive_prob], feed_dict= feed_dict)\n",
    "        test_pos_prob = np.array(test_pos_prob)\n",
    "\n",
    "        if i == 0:\n",
    "            predicted_prob_maps = test_pos_prob[0,:,:,:]\n",
    "        else:\n",
    "            predicted_prob_maps = np.vstack((predicted_prob_maps, test_pos_prob[0,:,:,:]))\n",
    "\n",
    "    print('Test data predicted')\n",
    "    \n",
    "    # test_positive_prob gives the output probability map that can be used as an input to the test function\n",
    "    return predicted_prob_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1015,
     "status": "error",
     "timestamp": 1596009828931,
     "user": {
      "displayName": "luna Maris",
      "photoUrl": "",
      "userId": "11926190777962497382"
     },
     "user_tz": -120
    },
    "id": "LTXphf7Sltfl",
    "outputId": "3a46db97-99fb-4b5a-85b0-e761aea6a7aa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a44c641c0772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_annot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReload_and_Predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDrop_Prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInit_Filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir_trained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_dir_model\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Reload_and_Predict' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_annot = Reload_and_Predict(test_images, test_annotations, Drop_Prob = 0.1, Init_Filters = 64, log_dir_trained_model = log_dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQ3-lhXjltfr"
   },
   "source": [
    "Beneith some functions are indicated that can be used to evaluate the trained model. They are all brought together in the Evaluate funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duNuxs-hltfr"
   },
   "outputs": [],
   "source": [
    "def ROC(pred_probs, true_probs, plot = True):\n",
    "    '''\n",
    "    This function calculates the ROC-AUC value\n",
    "    and it also calculates and visualizes the ROC-curve (if plot is true)\n",
    "    '''\n",
    "    \n",
    "    # calculate and print out ROC-AUC value\n",
    "    ROC_AUC = roc_auc_score(true_probs, pred_probs)\n",
    "    \n",
    "    # calculate and plot the ROC-curve\n",
    "    if plot:\n",
    "        FPRate, TPRate, Thresh = roc_curve(true_probs, pred_probs)\n",
    "        plt.figure()\n",
    "        plt.plot(FPRate, TPRate)\n",
    "        plt.title('ROC curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "    return ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5H_DmGBHltft"
   },
   "outputs": [],
   "source": [
    "def PRC(pred_probs, true_probs, plot = True):\n",
    "    '''\n",
    "    Calculate the aupr value = the area under the precision-recall curve\n",
    "    and plot the precision-recall curve (if plot is true)\n",
    "    '''\n",
    "    \n",
    "    # calculate the precision-recall curve\n",
    "    Precision, Recall, Thresh = precision_recall_curve(true_probs, pred_probs)\n",
    "    Precision = np.fliplr([Precision])[0]  # so the array is increasing (you won't get negative AUC)\n",
    "    Recall = np.fliplr([Recall])[0]  # so the array is increasing (you won't get negative AUC)\n",
    "    AUPR = np.trapz(Precision, Recall)\n",
    "      \n",
    "    \n",
    "    # plot the precision-recall curve\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(Precision, Recall)\n",
    "        plt.title('Precision-Recall curve')\n",
    "        plt.xlabel('Precision')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.show()\n",
    "    \n",
    "    return AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0D0-w7Eltfv"
   },
   "outputs": [],
   "source": [
    "def ConfusionMatrix(pred_probs, true_probs, threshold_confusion = 0.5):\n",
    "    '''\n",
    "    Calculate and print out the confusion matrix\n",
    "    The values for the confusion matrix are also returned\n",
    "    A standard threhsold of 0.5 is used to calculate the confusion matrix\n",
    "    '''\n",
    "    # print out the threshold that is used for the confusion matrix\n",
    "    print(\"Confusion matrix with a used threshold of {} for the positive class:\".format(threshold_confusion))\n",
    "    \n",
    "    # turn the predicted probability maps into binary outputs according to the threshold\n",
    "    thresh_pred_probs = np.empty((pred_probs.shape[0]))\n",
    "    for i in range(pred_probs.shape[0]):\n",
    "        if pred_probs[i] >= threshold_confusion:\n",
    "            thresh_pred_probs[i] = 1\n",
    "        else:\n",
    "            thresh_pred_probs[i] = 0\n",
    "    \n",
    "    # calculate the confusion-matrix and print it out\n",
    "    TN, FP, FN, TP = confusion_matrix(true_probs, thresh_pred_probs).ravel()\n",
    "    print('Amount of true positives: {}'.format(TP))\n",
    "    print('Amount of false positives: {}'.format(FP))\n",
    "    print('Amount of true negatives: {}'.format(TN))\n",
    "    print('Amount of false negatives: {}'.format(FN))\n",
    "    \n",
    "    return TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2J9K_4CXltfy"
   },
   "outputs": [],
   "source": [
    "def Metrics(tn, fp, fn, tp):\n",
    "    '''Print out some metrics like the accuracy, specificity, sensitivity and precision'''\n",
    "    \n",
    "    print('Some metrics:')\n",
    "    \n",
    "    # print out accuracy\n",
    "    accuracy = 0\n",
    "    if (tn+fp+fn+tp) != 0:\n",
    "        accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    print('Accuracy: {}'.format(accuracy))\n",
    "    \n",
    "    # print out specificity\n",
    "    specificity = 0\n",
    "    if (tn+fp) != 0:\n",
    "        specificity = tn/(tn+fp)\n",
    "    print('Specificity: {}'.format(specificity))\n",
    "    \n",
    "    # print out sensitivity\n",
    "    sensitivity = 0\n",
    "    if (tp+fn) != 0:\n",
    "        sensitivity = tp/(tp+fn)\n",
    "    print('Sensitivity: {}'.format(sensitivity))\n",
    "    \n",
    "    # print out precision\n",
    "    precision = 0\n",
    "    if (tp+fp) != 0:\n",
    "        precision = tp/(tp+fp)\n",
    "    print('Precision: {}'.format(precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yb1w7jtWltf0"
   },
   "outputs": [],
   "source": [
    "# evaluation of the model\n",
    "def Evaluate(pred_prob_maps, true_prob_maps):\n",
    "    '''\n",
    "    Evaluation of the network, based on comparisson between the true and predicted outputs\n",
    "    '''\n",
    "    print('Evaluating the model...')\n",
    "    \n",
    "    # creat a 1D numpy array with the predicted and true outputs\n",
    "    pred_prob_maps = pred_prob_maps.reshape(-1)\n",
    "    true_prob_maps = true_prob_maps.reshape(-1)\n",
    "\n",
    "    # print out ROC-AUC value and plot the ROC-curve\n",
    "    ROC_AUC = ROC(pred_prob_maps, true_prob_maps)\n",
    "    print('Area under the ROC curve: {}'.format(ROC_AUC))\n",
    "\n",
    "    # print out area under the precision-recall curve, AUPR value\n",
    "    AUPR = PRC(pred_prob_maps, true_prob_maps)\n",
    "    print('Area under Precision-Recall curve: {}'.format(AUPR))\n",
    "    \n",
    "    # print out confusion matrix\n",
    "    TN, FP, FN, TP = ConfusionMatrix(pred_prob_maps, true_prob_maps)\n",
    "    \n",
    "    # print out some metrics\n",
    "    Metrics(TN, FP, FN, TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lc3-uk51ltf2"
   },
   "outputs": [],
   "source": [
    "Evaluate(predicted_annot, test_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eog-QtTMmSu4"
   },
   "source": [
    "The functions beneith can be used to perform a gridsearch over different combinations of parameters to define the parametercombination that gives the best results in terms of performance and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-Cb8VYnltf4"
   },
   "outputs": [],
   "source": [
    "# gridsearch: look for the most optimal hyperparameters, making use of cross-validation\n",
    "\n",
    "# for this a separate validation set has to be defined\n",
    "# three fold cross-validation is performed in this case\n",
    "def ThreeFoldSplit(n_split):\n",
    "    '''\n",
    "    This function calculates a three-fold split of the train_images and train_annotations\n",
    "    Depending on n_split another train and validation set is defined\n",
    "    '''\n",
    "    \n",
    "    a = train_images.shape[0]\n",
    "    b = int(a/3)\n",
    "    \n",
    "    val_images = train_images[n_split*b:(n_split+1)*b]\n",
    "    val_annotations = train_annotations[n_split*b:(n_split+1)*b]\n",
    "    \n",
    "    # split the train set in to three parts\n",
    "    if n_split == 0:\n",
    "        tr_images = train_images[b:]\n",
    "        tr_annotations = train_annotations[b:]\n",
    "        \n",
    "    if n_split == 1:\n",
    "        tr_images = np.vstack((train_images[0:b], train_images[2*b:]))\n",
    "        tr_annotations = np.vstack((train_annotations[0:b], train_annotations[2*b:]))\n",
    "        \n",
    "    if n_split == 2:\n",
    "        tr_images = train_images[0:2*b]\n",
    "        tr_annotations = train_annotations[0:2*b]\n",
    "    \n",
    "    return tr_images, tr_annotations, val_images, val_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQbJLfkFltf7"
   },
   "outputs": [],
   "source": [
    "# function to choose the best hyperparameter combination based on model performance in terms of the ROC AUC score\n",
    "def Hyperparam_Optimization(lr_list, Batch_Size_list, dropout_list, loss_func_list, optim_list, \n",
    "                            init_filters_list, epochs_list, filename):\n",
    "    n = 0\n",
    "    file = open('/content/drive/My Drive/Stage_ENT_Studios/Unet/GridSearchResults/'+filename+'.txt','w') \n",
    "    for LearnRate in lr_list:\n",
    "        for BatchSize in Batch_Size_list:\n",
    "            for Dropout in dropout_list:\n",
    "                for LossFunc in loss_func_list:\n",
    "                    for Optim in optim_list:\n",
    "                        for InitFilters in init_filters_list:\n",
    "                            for Epoch in epochs_list:\n",
    "                                \n",
    "                                n +=1\n",
    "                                print('Evaluating parameter combination {} ...'.format(n))\n",
    "                                    \n",
    "                                AUC_list = []\n",
    "                                AUPR_list = []\n",
    "                                Loss_list = []\n",
    "                                time_list = []\n",
    "                                # 3-fold cross-validation is used to evaluate the model \n",
    "                                # for a certain param combination \n",
    "                                for fold in range(3):\n",
    "                                        \n",
    "                                    tr_images, tr_annotations, val_images, val_annotations = ThreeFoldSplit(fold)\n",
    "                                    \n",
    "                                    # fitting the model to the data for a certain fold and defining the auc, aupr and loss\n",
    "                                    start_time = time.time()\n",
    "                                    \n",
    "                                    val_loss, val_auc, val_aupr = train_network(tr_images, tr_annotations, val_images, val_annotations, Dropout, InitFilters, BatchSize, LossFunc, Optim, \n",
    "                                                  LearnRate, Epoch, SaveResults = False)\n",
    "                                    \n",
    "                                    end_time = time.time()\n",
    "                        \n",
    "                                    # the ROC auc value and the PR auc value can be compared to each other\n",
    "                                    # for different param combinations\n",
    "                                        \n",
    "                                    # creat a 1D numpy array with the predicted and true outputs   \n",
    "                                    AUC_list.append(val_auc)\n",
    "                                    AUPR_list.append(val_aupr)\n",
    "                                    Loss_list.append(val_loss) \n",
    "                                    time_list.append(end_time-start_time) \n",
    "                                    \n",
    "                                # calculate the mean and standard-dev of the AUC, AUPR, loss and time for all three folds\n",
    "                                mean_AUC = np.mean(np.array(AUC_list), axis = 0)\n",
    "                                std_AUC = np.std(np.array(AUC_list), axis = 0)\n",
    "                                mean_AUPR = np.mean(np.array(AUPR_list), axis = 0)\n",
    "                                std_AUPR = np.std(np.array(AUPR_list), axis = 0)\n",
    "                                mean_Loss = np.mean(np.array(Loss_list), axis = 0)\n",
    "                                std_Loss = np.std(np.array(Loss_list), axis = 0)\n",
    "                                mean_time = np.mean(time_list, axis = 0)\n",
    "                                    \n",
    "                                # print out these values together with the training time for this parameter set\n",
    "                                print('Hyperparameter combination:')\n",
    "                                print('learning rate {}, batch size {}, dropout {}, loss function {},optimization {}, initial amount of filters {} and amount of epochs {}'.format(LearnRate, BatchSize, Dropout, LossFunc, Optim, InitFilters, Epoch))\n",
    "                                print('Results:')\n",
    "                                print('AUC mean: {} and standard deviation: {}'.format(mean_AUC, std_AUC))\n",
    "                                print('AUPR mean: {} and standard deviation: {}'.format(mean_AUPR, std_AUPR)) \n",
    "                                print('Loss mean: {} and standard deviation: {}'.format(mean_Loss, std_Loss)) \n",
    "                                print('training time: {}'.format(mean_time))\n",
    "\n",
    "                                # save all values in a txt file\n",
    "                                file.write('Hyperparameter combination: \\n')\n",
    "                                file.write('learning rate {}, batch size {}, dropout {}, loss function {},optimization {}, initial amount of filters {}, amount of epochs {} \\n'.format(LearnRate, BatchSize, Dropout, LossFunc, Optim, InitFilters, Epoch))\n",
    "                                file.write('AUC mean: {} and standard deviation: {} \\n'.format(mean_AUC, std_AUC))\n",
    "                                file.write('AUPR mean: {} and standard deviation: {} \\n'.format(mean_AUPR, std_AUPR))\n",
    "                                file.write('Loss mean: {} and standard deviation: {} \\n'.format(mean_Loss, std_Loss))\n",
    "                                file.write('training time: {} \\n'.format(mean_time))\n",
    "                                file.write(' \\n')\n",
    "\n",
    "    file.close() \n",
    "                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kL85YGBWltf-"
   },
   "outputs": [],
   "source": [
    "# different options that have to be tried\n",
    "# learn rat\n",
    "LR_list = [tf.Variable(1e-4, dtype=tf.float32), tf.Variable(1e-5, dtype=tf.float32), tf.Variable(1e-6, dtype=tf.float32)]\n",
    "# batch size\n",
    "BS_list = [3,6]\n",
    "# drop probab\n",
    "DP_list = [0.1,0.3]\n",
    "# loss function\n",
    "LF_list = ['UNet_loss'] # Sfce loss can not really be used in this case\n",
    "# optimisation function\n",
    "OF_list = ['Adam', 'sgd']\n",
    "# initial amount of filters\n",
    "IF_list = [64, 32, 16]\n",
    "# amount of epochs\n",
    "EP_list = [10, 50]\n",
    "# alpha and gamma, parameters of the focal loss function\n",
    "\n",
    "Hyperparam_Optimization(lr_list = LR_list, Batch_Size_list = BS_list, dropout_list = DP_list, \n",
    "                        loss_func_list = LF_list, optim_list = OF_list, init_filters_list = IF_list, \n",
    "                        epochs_list = EP_list, filename = 'GridSearch_UNet_Softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Xi_6BtdltgA"
   },
   "outputs": [],
   "source": [
    "# to visualize some predictions\n",
    "def PlotImage(image_array, database = '', image_name = '', save = False, savepath = ''):\n",
    "    '''Visualize (and save if desired) an image represented by a numpy array'''\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(database+': '+image_name)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.imshow(image_array, cmap=plt.cm.Greys_r)\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(savepath+database+'_'+image_name+'.png')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rb7SKKRvk95r"
   },
   "outputs": [],
   "source": [
    "annotation = predicted_annot[0]\n",
    "positives = np.where(annotation > 0.5)\n",
    "bin_annotation = np.zeros(annotation.shape)\n",
    "bin_annotation[positives] = 1\n",
    "PlotImage(annotation)\n",
    "PlotImage(bin_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzK2Ng7ZltgC"
   },
   "source": [
    "To kill an active tensorboard session:\n",
    "Go to the anaconda prompt and type:\n",
    "\n",
    "taskkill /im tensorboard.exe /f\n",
    "\n",
    "del /q %TMP%\\.tensorboard-info\\*\n",
    "\n",
    "\n",
    "or in the windows command prompt:\n",
    "\n",
    "taskkill /IM \"tensorboard.exe\" /F"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNet_Softmax.ipynb",
   "provenance": [
    {
     "file_id": "1ko8HCMMTNlaR1MCC-1f6QL1uAaqzHXwO",
     "timestamp": 1595928299309
    },
    {
     "file_id": "1cjKN36peUbhC36sgbu1cp5rwTPmzAtcg",
     "timestamp": 1595852695030
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
