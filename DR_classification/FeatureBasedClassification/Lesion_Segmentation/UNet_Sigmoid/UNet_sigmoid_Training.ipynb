{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ga1Mx266ltfH"
   },
   "source": [
    "This script is used to perform lesion segmentation in fundus photographs. The lesions that can be segmented are hard exudates, soft exudates, microaneurysms and hemorrhages. The segmentation is based on a UNet, a CNN that takes an image as an input and that outputs a probability map indicating for every pixel the probability of belonging to a certain type of lesion or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4461,
     "status": "ok",
     "timestamp": 1596186896190,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "Gf8WnH-elznb",
    "outputId": "5b815821-3fa0-4ec1-d653-cdd578fc6df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorlayer==1.11.1 in /usr/local/lib/python3.6/dist-packages (1.11.1)\n",
      "Requirement already satisfied: scipy<1.2,>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.1.0)\n",
      "Requirement already satisfied: imageio<2.5,>=2.3 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (2.4.1)\n",
      "Requirement already satisfied: scikit-image<0.15,>=0.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (0.14.5)\n",
      "Requirement already satisfied: matplotlib<3.1,>=2.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (3.0.3)\n",
      "Requirement already satisfied: wrapt<1.11,>=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.10.11)\n",
      "Requirement already satisfied: requests<2.21,>=2.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (2.20.1)\n",
      "Requirement already satisfied: scikit-learn<0.21,>=0.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (0.20.4)\n",
      "Requirement already satisfied: progressbar2<3.39,>=3.38 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (3.38.0)\n",
      "Requirement already satisfied: tqdm<4.29,>=4.23 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (4.28.1)\n",
      "Requirement already satisfied: lxml<4.3,>=4.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (4.2.6)\n",
      "Requirement already satisfied: numpy<1.16,>=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.11.1) (1.15.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<2.5,>=2.3->tensorlayer==1.11.1) (7.0.0)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (2.4)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (1.3.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (1.1.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (1.15.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer==1.11.1) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (1.24.3)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer==1.11.1) (2.7)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2<3.39,>=3.38->tensorlayer==1.11.1) (2.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image<0.15,>=0.14->tensorlayer==1.11.1) (4.4.2)\n",
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorlayer==1.11.1\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8397,
     "status": "ok",
     "timestamp": 1596186909348,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "9eyAksxJOFsi",
    "outputId": "dfc3b110-a4a9-4c7d-b0f8-3ca31a58c1b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/core.py:39: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/pooling.py:66: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import tensorlayer.layers as tll\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tl.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26743,
     "status": "ok",
     "timestamp": 1596186928970,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "GnA-4iHSuYJf",
    "outputId": "ede37f80-c469-4d4e-9044-e6e7e3b60a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# read in train and test data in case Google DRIVE is used\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4SbTTqBltfN"
   },
   "outputs": [],
   "source": [
    "# read in the train and test data for a certain lesion type\n",
    "\n",
    "# Basepath depends on the lesion\n",
    "# LesionType = 'SoftExudates'\n",
    "LesionType = 'HardExudates'\n",
    "# LesionType = 'Microaneurysms'\n",
    "# LesionType = 'Hemorrhages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67048,
     "status": "ok",
     "timestamp": 1596186996023,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "Na905WmrltfS",
    "outputId": "125eddcd-7fe1-4610-9a7c-650efa949694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train images: (324, 512, 512, 3)\n",
      "Shape train annotations: (324, 512, 512)\n",
      "Shape test images: (156, 512, 512, 3)\n",
      "Shape test annotations: (156, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Basepath for Google DRIVE:\n",
    "# Basepath = '/content/drive/My Drive/Stage_ENT_Studios/Data/IDRiD/' + LesionType + '/Arrays/'\n",
    "\n",
    "# Basepath for Jupyter notebooks:\n",
    "Basepath = 'C:/Users/lunam/Documents/1steMaster/Stage/Data_FinalArrays/IDRiD/'+ LesionType+'/Arrays/'\n",
    "\n",
    "# train data\n",
    "train_images = np.float32(np.load(Basepath + 'train_images_Final.npy'))\n",
    "print('Shape train images: {}'.format(train_images.shape))\n",
    "\n",
    "train_annotations =  np.int32(np.load(Basepath + 'train_annotations_Final.npy'))\n",
    "# train_annotations = np.expand_dims(train_annotations, axis = 3)\n",
    "print('Shape train annotations: {}'.format(train_annotations.shape))\n",
    "\n",
    "# test data\n",
    "test_images = np.float32(np.load(Basepath + 'test_images_Final.npy'))\n",
    "print('Shape test images: {}'.format(test_images.shape))\n",
    "\n",
    "test_annotations = np.int32(np.load(Basepath + 'test_annotations_Final.npy'))\n",
    "# test_annotations = np.expand_dims(test_annotations, axis = 3)\n",
    "print('Shape test annotations: {}'.format(test_annotations.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWjV59oPltfZ"
   },
   "outputs": [],
   "source": [
    "# save directions for the model and the tensorboard logs\n",
    "\n",
    "# Base path for Google DRIVE:\n",
    "# base_path = '/content/drive/My Drive/Stage_ENT_Studios/Unet/Logs/'\n",
    "\n",
    "# Base path for jupyter notebooks:\n",
    "base_path = 'C:/Users/lunam/Documents/1steMaster/Stage/Code_Final/DR_classification/FeatureBasedClassification/UNet_Sigmoid/Logs/'+LesionType+'/'\n",
    "\n",
    "# direction where the tensorboard files will be stored\n",
    "log_dir_tens = base_path + 'Tensorboard_Logs/'\n",
    "# direction where the trained models will be stored\n",
    "log_dir_model = base_path + 'Trained_Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05Xofm8P4hR9"
   },
   "outputs": [],
   "source": [
    "class BatchData():\n",
    "    '''\n",
    "    This class is used to create batches of images with their corresponding annotations\n",
    "    These batches can then be fed to the Unet\n",
    "    The numpy arrays of preprocessed images and corresponding annotations are given as an input to the class\n",
    "    '''\n",
    "    \n",
    "    # resetting all values in case a new batch dataset is created\n",
    "    images = []\n",
    "    annotations = []\n",
    "    batch_offset = 0\n",
    "    epochs_completed = 0 \n",
    "\n",
    "\n",
    "    def __init__(self, image_arrays, annotation_arrays):\n",
    "        \n",
    "        print(\"Initializing Batch Dataset Reader...\")\n",
    "        \n",
    "        self.images = image_arrays\n",
    "        self.annotations = annotation_arrays\n",
    "\n",
    "        # resize the annotations to indicate that there is only one channel in this case\n",
    "        self.annotations = np.expand_dims(self.annotations, 3)\n",
    "        # this makes a binary mask of the annotations, there where annotations has a pixel value above 0, the pixel value will be set to 1\n",
    "        # there where the pixel value is 0 or smaller, the pixel value is set to 0\n",
    "        self.annotations = np.where(self.annotations>0, 1, 0)\n",
    "        \n",
    "        print ('Shape images: {}'.format(self.images.shape))\n",
    "        print ('Shape annotations: {}'.format(self.annotations.shape))\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        '''\n",
    "        This function can be used to everytime find the next batch of images and corresponding annotations\n",
    "        The size of the batches is defined by the batch_size\n",
    "        '''\n",
    "        \n",
    "        # start image of the batch\n",
    "        start = self.batch_offset\n",
    "        # set the starting value for the next batch\n",
    "        self.batch_offset += batch_size \n",
    "        \n",
    "        # all data has already been used\n",
    "        if self.batch_offset > self.images.shape[0]:\n",
    "            \n",
    "            # images and annotations get shuffled randomly for the next epoch\n",
    "            perm = np.arange(self.images.shape[0])\n",
    "            np.random.shuffle(perm)\n",
    "            self.images = self.images[perm]\n",
    "            self.annotations = self.annotations[perm]\n",
    "            \n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self.batch_offset = batch_size\n",
    "        \n",
    "        # end image of the batch\n",
    "        end = self.batch_offset\n",
    "        \n",
    "        # return the images and corresponding annotations in this batch\n",
    "        return self.images[start:end], self.annotations[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55GrGQj34IK8"
   },
   "outputs": [],
   "source": [
    "def LoadBatchData(Train_Images, Train_Annotations, Test_Images, Test_Annotations):\n",
    "    '''\n",
    "    This function creates a batch dataset for the train and test set\n",
    "    '''\n",
    "    \n",
    "    # create a batchdataset for the train set\n",
    "    train_batch_data = BatchData(Train_Images, Train_Annotations)\n",
    "            \n",
    "    # create a batchdataset for the test set\n",
    "    test_batch_data = BatchData(Test_Images, Test_Annotations)\n",
    "            \n",
    "    # return the train and test batch dataset\n",
    "    return train_batch_data, test_batch_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FICWJHVxltfh"
   },
   "outputs": [],
   "source": [
    "# The UNet network\n",
    "def UNet(image, drop_prob = 0.1, init_filters = 64, is_train = True):\n",
    "    '''This function defines the original UNet network'''\n",
    "    \n",
    "    # initialization of the weights\n",
    "    W_init = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "    # Unet network\n",
    "                \n",
    "    # LEFT part\n",
    "    # input layer\n",
    "    input_image = tl.layers.InputLayer(image)\n",
    "            \n",
    "    # Convolutional block 1\n",
    "    conv2d_1 = tl.layers.Conv2d(input_image, init_filters, (3, 3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_2 = tl.layers.Conv2d(conv2d_1, init_filters, (3, 3), act= tf.nn.relu, W_init= W_init)\n",
    "    pool_1 = tl.layers.MaxPool2d(conv2d_2, (2, 2), (2, 2), name= 'maxpool_1')\n",
    "    dropout_1 = tl.layers.DropoutLayer(pool_1, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 2\n",
    "    conv2d_3 = tl.layers.Conv2d(dropout_1, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_4 = tl.layers.Conv2d(conv2d_3, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    pool_2 = tl.layers.MaxPool2d(conv2d_4, (2,2), (2, 2), name='maxpool_2')\n",
    "    dropout_2 = tl.layers.DropoutLayer(pool_2, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 3\n",
    "    conv2d_5 = tl.layers.Conv2d(dropout_2, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_6 = tl.layers.Conv2d(conv2d_5, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    pool_3 = tl.layers.MaxPool2d(conv2d_6, (2,2), (2, 2), name='maxpool_3')\n",
    "    dropout_3 = tl.layers.DropoutLayer(pool_3, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # Convolutional block 4\n",
    "    conv2d_7 = tl.layers.Conv2d(dropout_3, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_8 = tl.layers.Conv2d(conv2d_7, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    pool_4 = tl.layers.MaxPool2d(conv2d_8, (2,2), (2, 2), name='maxpool_4')\n",
    "    dropout_4 = tl.layers.DropoutLayer(pool_4, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "                \n",
    "    # MIDDLE part\n",
    "    conv2d_9 = tl.layers.Conv2d(dropout_4, 16*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_10 = tl.layers.Conv2d(conv2d_9, 16*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "                \n",
    "                \n",
    "    # RIGHT part\n",
    "    # Convolutional block 1\n",
    "    upsampling_1 = tl.layers.UpSampling2dLayer(conv2d_10, (2,2))\n",
    "    concat_1 = tl.layers.ConcatLayer([upsampling_1, conv2d_8], 3)\n",
    "    dropout_5 = tl.layers.DropoutLayer(concat_1, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_11 = tl.layers.Conv2d(dropout_5, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_12 = tl.layers.Conv2d(conv2d_11, 8*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "                \n",
    "    # Convolutional block 2\n",
    "    upsampling_2 = tl.layers.UpSampling2dLayer(conv2d_12, (2,2))\n",
    "    concat_2 = tl.layers.ConcatLayer([upsampling_2, conv2d_6], 3)\n",
    "    dropout_6 = tl.layers.DropoutLayer(concat_2, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_13 = tl.layers.Conv2d(dropout_6, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "    conv2d_14 = tl.layers.Conv2d(conv2d_13, 4*init_filters, (3,3), act= tf.nn.relu, W_init=W_init)\n",
    "            \n",
    "                \n",
    "    # Convolutional block 3\n",
    "    upsampling_3 = tl.layers.UpSampling2dLayer(conv2d_14, (2,2))\n",
    "    concat_3 = tl.layers.ConcatLayer([upsampling_3,conv2d_4], 3)\n",
    "    dropout_7 = tl.layers.DropoutLayer(concat_3, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_15 = tl.layers.Conv2d(dropout_7, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_16 = tl.layers.Conv2d(conv2d_15, 2*init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "                \n",
    "    # Convolutional block 4\n",
    "    upsampling_4 = tl.layers.UpSampling2dLayer(conv2d_16, (2,2))\n",
    "    concat_4 = tl.layers.ConcatLayer([upsampling_4,conv2d_2], 3)\n",
    "    dropout_8 = tl.layers.DropoutLayer(concat_4, keep= 1-drop_prob, is_fix = True, is_train=is_train)\n",
    "    conv2d_17 = tl.layers.Conv2d(dropout_8, init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "    conv2d_18 = tl.layers.Conv2d(conv2d_17, init_filters, (3,3), act= tf.nn.relu, W_init= W_init)\n",
    "                \n",
    "                \n",
    "    # ouput layer\n",
    "    output_image = tl.layers.Conv2d(conv2d_18, 1, (1,1), W_init= W_init) \n",
    "\n",
    "    # logits tensor, often a step inbetween befor a softmax activation is applied (size im_size x im_size, 2)\n",
    "    logits = output_image.outputs\n",
    "\n",
    "    # the model\n",
    "    model = output_image\n",
    "\n",
    "    # a binary output map with size im_size x im_size can be found by applying the argmax operation\n",
    "    # this operation yields 0 or 1 for every pixel position depending on whether the value in the first or second image is the largest\n",
    "    binary_prediction = tf.math.argmax(logits, axis= 3, name= 'prediction')\n",
    "        \n",
    "    return binary_prediction, logits, output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXe-N1A0JgM5"
   },
   "outputs": [],
   "source": [
    "# define some different losses\n",
    "def loss_UNet(predicted_logits, real_annotations):\n",
    "\n",
    "    real_annotations = tf.convert_to_tensor(real_annotations)\n",
    "    real_annotations = tf.cast(real_annotations, tf.float32)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels= real_annotations, logits= predicted_logits)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# define the focal cross entropy loss function\n",
    "# loss function has to be defined in a way to avoid data inbalance\n",
    "def loss_sfce(predicted_logits, real_annotations, alpha = 0.25, gamma = 2.0):\n",
    "    '''\n",
    "    This type of loss function tries to avoid data imbalance in image segmentation\n",
    "    There are two parameters alpha and gamma, the default values are indicated\n",
    "    gamma should always be greater than or equal to 0\n",
    "    '''\n",
    "    print('calculating loss')\n",
    "    \n",
    "    predicted_logits = tf.convert_to_tensor(predicted_logits)\n",
    "    real_annotations = tf.convert_to_tensor(real_annotations)\n",
    "    real_annotations = tf.cast(real_annotations, tf.float32)\n",
    "    \n",
    "    # classic binary cross_entropy is calculated\n",
    "    ce = K.binary_crossentropy(real_annotations, predicted_logits, from_logits= True)\n",
    "\n",
    "    # binary cross-entropy is multiplied with two factors: alpha and modulating factor\n",
    "    # convert the logits predictions into probabilities\n",
    "    alpha_factor = 1.0\n",
    "    modulating_factor = 1.0\n",
    "    \n",
    "    pred_prob = tf.sigmoid(predicted_logits)\n",
    "    \n",
    "    if alpha:\n",
    "        alpha = tf.convert_to_tensor(alpha, dtype=K.floatx())\n",
    "        alpha_factor = real_annotations * alpha + (1 - real_annotations) * (1 - alpha)\n",
    "\n",
    "\n",
    "    p_t = (real_annotations * pred_prob) + ((1 - real_annotations) * (1 - pred_prob))\n",
    "    if gamma:\n",
    "        gamma = tf.convert_to_tensor(gamma, dtype=K.floatx())\n",
    "        modulating_factor = tf.pow((1.0 - p_t), gamma)\n",
    "\n",
    "    # compute the final loss and return\n",
    "    return tf.reduce_mean(alpha_factor * modulating_factor * ce)\n",
    "\n",
    "\n",
    "\n",
    "# Asymmetric similarity loss function, to balance recall and precision\n",
    "# the larger beta, the more important the recall becomes relative to the precision\n",
    "def loss_asl(predicted_logits, real_annotations, beta = 2):\n",
    "    real_annotations = real_annotations[:,:,:,0]\n",
    "    real_annotations = tf.cast(real_annotations, tf.float32)\n",
    "    pred_prob = tf.nn.sigmoid(predicted_logits)[:,:,:,0]\n",
    "    \n",
    "    prod_pos = pred_prob * real_annotations\n",
    "    sum_prod_pos = tf.reduce_sum(tf.reduce_sum(prod_pos, axis = 2), axis = 1)\n",
    "    prod_neg_pred = (1-pred_prob) * real_annotations\n",
    "    sum_prod_neg_pred = tf.reduce_sum(tf.reduce_sum(prod_neg_pred, axis = 2), axis = 1)\n",
    "    prod_neg_real = (pred_prob) * (1-real_annotations)\n",
    "    sum_prod_neg_real = tf.reduce_sum(tf.reduce_sum(prod_neg_real, axis = 2), axis = 1)\n",
    "\n",
    "    beta = tf.convert_to_tensor(beta, dtype=K.floatx())\n",
    "\n",
    "    num = (1+beta**2) * sum_prod_pos\n",
    "    denom = (1+beta**2) *sum_prod_pos + beta**2 * sum_prod_neg_pred + sum_prod_neg_real\n",
    "\n",
    "    loss = num/denom\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_Pr5rblUvBD"
   },
   "outputs": [],
   "source": [
    "# define some optimizers and apply them to the network\n",
    "def Adam_optimization(losses, lr = 0.001):\n",
    "    '''This function defines the Adam optimizer that will be used and applies it to optimize the weights during training'''\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "    train_variables_list = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(losses, var_list= train_variables_list)\n",
    "    train_optimization = optimizer.apply_gradients(gradients)\n",
    "            \n",
    "    return train_optimization\n",
    "\n",
    "def SGD_optimization(losses, lr = 0.001):\n",
    "    '''This function defines the Stochastic gradient descent optimizer that will be used and applies it to optimize the weights during trainin'''\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = lr)\n",
    "    train_variables_list = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(losses, var_list= train_variables_list)\n",
    "    train_optimization = optimizer.apply_gradients(gradients)\n",
    "\n",
    "    return train_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQg7qWs9Wo9r"
   },
   "outputs": [],
   "source": [
    "def train_network(TrainImages, TrainAnnotations, TestImages, TestAnnotations, \n",
    "                  Drop_Prob = 0.1, Init_Filters = 64, batch_size = 3, loss_function = 'UNet_loss', optim = 'Adam', \n",
    "                  learning_rate = tf.Variable(1e-5, dtype=tf.float32), MAX_EPOCH = 10, SaveResults = True, print_freq = 1):\n",
    "    '''\n",
    "    This function trains the UNet on the indicated train data with corresponding annotations\n",
    "    At the end the trained model is being saved\n",
    "    '''\n",
    "\n",
    "    # placeholders are created, variables to which data is assigned later on\n",
    "    print('Create placeholders')\n",
    "    image = tf.placeholder(tf.float32, [None,512,512, 3], name= 'image')\n",
    "    annotation = tf.placeholder(tf.int32, shape=[None, 512, 512, 1], name= \"annotation\")\n",
    "\n",
    "    # define the model that will be used for training and for testing\n",
    "    print('Define the model for training')\n",
    "    train_pred, train_logits, train_network = UNet(image, drop_prob = Drop_Prob, init_filters = Init_Filters, is_train = True)\n",
    "    print('Define the model for testing')\n",
    "    test_pred, test_logits, test_network = UNet(image, drop_prob = Drop_Prob, init_filters = Init_Filters, is_train = False)\n",
    "    \n",
    "    # define the output probability maps, losses and optimization for training and testing\n",
    "    print('Define outputs, losses and optimization')\n",
    "    # sigmoid activation creates a probability map which is the output\n",
    "    train_positive_prob = tf.nn.sigmoid(train_logits)\n",
    "    test_positive_prob = tf.nn.sigmoid(test_logits)\n",
    "    # loss function\n",
    "    if loss_function == 'UNet_loss':\n",
    "        train_loss_op = loss_UNet(train_logits, annotation)\n",
    "        test_loss_op= loss_UNet(test_logits, annotation)\n",
    "    elif loss_function == 'Sfce_loss':\n",
    "        train_loss_op = loss_sfce(train_logits, annotation, alpha = 0.25, gamma = 2.0)\n",
    "        test_loss_op= loss_sfce(test_logits, annotation, alpha = 0.25, gamma = 2.0)\n",
    "    elif loss_function == 'Asl_loss':\n",
    "        train_loss_op = loss_asl(train_logits, annotation)\n",
    "        test_loss_op= loss_asl(test_logits, annotation)\n",
    "    # optimization\n",
    "    if optim == 'Adam':\n",
    "        train_op = Adam_optimization(train_loss_op, learning_rate)\n",
    "    elif optim == 'sgd':\n",
    "        train_op = SGD_optimization(train_loss_op, learning_rate)\n",
    "        \n",
    "    # learning_rate decay at higher amounts of epochs \n",
    "    lr_assign_op = tf.assign(learning_rate, learning_rate / 10)\n",
    "    \n",
    "\n",
    "    # a session should be started in which all intermediate results are stored (also weights of the network for example)\n",
    "    sess = tf.Session()\n",
    "    # saving the train and test results and the trained model\n",
    "    if SaveResults:\n",
    "        # creating summary which stores the results that can be visualised with tensorboard\n",
    "        print(\"Setting up summary...\")\n",
    "        # test_summary_op = tf.summary.merge_all()\n",
    "        # creating saver, used to save the trained model at the end\n",
    "        print(\"Setting up Saver...\")\n",
    "        saver = tf.train.Saver(max_to_keep=2)\n",
    "        summary_writer = tf.summary.FileWriter(log_dir_tens, sess.graph)\n",
    "\n",
    "        \n",
    "    tl.layers.initialize_global_variables(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # define the train and test batches that can be fed into the network\n",
    "    train_batch_data, test_batch_data = LoadBatchData(TrainImages, TrainAnnotations, TestImages, TestAnnotations)\n",
    "\n",
    "    # defining the numer of steps per epoch, based on the batchsize\n",
    "    train_nbr = TrainImages.shape[0]\n",
    "    test_nbr = TestImages.shape[0]\n",
    "    step_every_epoch = int(train_nbr/batch_size)\n",
    "    test_every_epoch = int(test_nbr/batch_size)\n",
    "    \n",
    "    # go over all epochs of training\n",
    "    for epo in range(1,MAX_EPOCH+1):\n",
    "        \n",
    "        # time is defined at the start of every epoch\n",
    "        start_time = time.time()\n",
    "        # resetting of all variables\n",
    "        train_loss, test_loss, train_aupr, test_aupr, train_auc, test_auc= 0, 0, 0, 0, 0, 0\n",
    "            \n",
    "        # go over all batches in one epoch\n",
    "        for s in range(step_every_epoch):\n",
    "        \n",
    "            # define the next batch to train the network\n",
    "            train_images_batch, train_annotations_batch = train_batch_data.next_batch(batch_size)\n",
    "            feed_dict = {image: train_images_batch, annotation: train_annotations_batch}\n",
    "            # train the network and define the output of the network for this batch of images\n",
    "            train_pos_prob, train_err, _ = sess.run([train_positive_prob, train_loss_op, train_op], feed_dict=feed_dict)\n",
    "\n",
    "            # auc and aupr score are calculated for this batch\n",
    "            temp_train_annotations = np.reshape(train_annotations_batch,-1)\n",
    "            temp_tra_positive_prob = np.reshape(train_pos_prob,-1)\n",
    "            train_sauc = ROC(temp_tra_positive_prob, temp_train_annotations, plot = False)\n",
    "            train_saupr = PRC(temp_tra_positive_prob, temp_train_annotations, plot = False)\n",
    "\n",
    "            # define the total loss, auc and aupr over all batches in 1 epoch\n",
    "            train_loss += train_err\n",
    "            train_auc += train_sauc\n",
    "            train_aupr += train_saupr\n",
    "            \n",
    "        # after every epoch, check whether results should be printed out and network should be tested\n",
    "        # print out after epoch 1 and then every print_freq\n",
    "        if epo % print_freq == 0 or epo == 1 or epo == (MAX_EPOCH):\n",
    "        \n",
    "            # average out loss, auc and aupr for the train set over all batches\n",
    "            train_loss = train_loss/step_every_epoch\n",
    "            train_auc = train_auc/step_every_epoch\n",
    "            train_aupr = train_aupr/step_every_epoch\n",
    "\n",
    "            # print out the training results\n",
    "            print('epoch {} took {}s'.format(epo, time.time() - start_time))\n",
    "            print('   train loss: {}'.format(train_loss))\n",
    "            print('   train auc: {}'.format(train_auc))\n",
    "            print('   train aupr: {}'.format(train_aupr))\n",
    "\n",
    "            if SaveResults:      \n",
    "                # save these values to visualize them later with tensorboard\n",
    "                train_summary = tf.Summary(value=[tf.Summary.Value(tag=\"train_loss\", simple_value=train_loss), tf.Summary.Value(tag=\"train_auc\", simple_value=train_auc),\n",
    "                                                tf.Summary.Value(tag=\"train_aupr\", simple_value=train_aupr)])\n",
    "                summary_writer.add_summary(train_summary, epo)\n",
    "                \n",
    "            # testing of the network\n",
    "            # test data is also subdivided in batches, go over all batches\n",
    "            for test_s in range(test_every_epoch):\n",
    "\n",
    "                # get the next batch of test data\n",
    "                test_images_batch, test_annotations_batch = test_batch_data.next_batch(batch_size)\n",
    "                # apply the network to the test images and define the output of the network and the loss\n",
    "                feed_dict= {image:test_images_batch, annotation:test_annotations_batch}\n",
    "                test_pos_prob, test_err = sess.run([test_positive_prob, test_loss_op], feed_dict= feed_dict)\n",
    "\n",
    "                # compute auc and aupr score for test set\n",
    "                temp_test_annotations = np.reshape(test_annotations_batch,-1)\n",
    "                temp_test_positive_prob = np.reshape(test_pos_prob,-1)\n",
    "                test_sauc = ROC(temp_test_positive_prob, temp_test_annotations, plot = False)\n",
    "                test_saupr= PRC(temp_test_positive_prob, temp_test_annotations, plot = False)\n",
    "\n",
    "                # calculate total loss, auc and aupr for the test set over all batches\n",
    "                test_loss += test_err\n",
    "                test_auc += test_sauc\n",
    "                test_aupr += test_saupr\n",
    "\n",
    "            # average loss, auc and aupr for the test set over all batches\n",
    "            test_loss = test_loss/test_every_epoch\n",
    "            test_auc = test_auc/test_every_epoch\n",
    "            test_aupr = test_aupr/test_every_epoch\n",
    "\n",
    "            # print out the test results\n",
    "            print('   test loss: {}'.format(test_loss))\n",
    "            print('   test auc: {}'.format(test_auc))\n",
    "            print('   test aupr: {}'.format(test_aupr))\n",
    "\n",
    "            if SaveResults:       \n",
    "                # save these values to visualize them later with tensorboard\n",
    "                test_summary = tf.Summary(value=[tf.Summary.Value(tag=\"test_loss\", simple_value=test_loss), tf.Summary.Value(tag=\"test_auc\", simple_value=test_auc), \n",
    "                                                tf.Summary.Value(tag=\"test_aupr\", simple_value=test_aupr)])\n",
    "                summary_writer.add_summary(test_summary, epo) \n",
    "\n",
    "                # tensorboard flush\n",
    "                summary_writer.flush() # the summary is written at this moment\n",
    "            \n",
    "        # at specific amounts of epochs, the learning rate should become smaller to work more precisely\n",
    "        if epo == int(MAX_EPOCH*2/3) or epo == int(MAX_EPOCH/2): \n",
    "            sess.run(lr_assign_op)\n",
    "            \n",
    "        # eventual saving of the fully trained model\n",
    "        if SaveResults: \n",
    "            if epo == MAX_EPOCH:\n",
    "                saver.save(sess, log_dir_model + \"model.ckpt\", epo)\n",
    "                print('epoch {}, the model has been saved successfully'.format(epo))\n",
    "\n",
    "    return test_loss, test_auc, test_aupr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duNuxs-hltfr"
   },
   "outputs": [],
   "source": [
    "def ROC(pred_probs, true_probs, plot = True):\n",
    "    '''\n",
    "    This function calculates the ROC-AUC value\n",
    "    and it also calculates and visualizes the ROC-curve (if plot is true)\n",
    "    '''\n",
    "    \n",
    "    # calculate and print out ROC-AUC value\n",
    "    ROC_AUC = roc_auc_score(true_probs, pred_probs)\n",
    "    \n",
    "    # calculate and plot the ROC-curve\n",
    "    if plot:\n",
    "        FPRate, TPRate, Thresh = roc_curve(true_probs, pred_probs)\n",
    "        plt.figure()\n",
    "        plt.plot(FPRate, TPRate)\n",
    "        plt.title('ROC curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "    return ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5H_DmGBHltft"
   },
   "outputs": [],
   "source": [
    "def PRC(pred_probs, true_probs, plot = True):\n",
    "    '''\n",
    "    Calculate the aupr value = the area under the precision-recall curve\n",
    "    and plot the precision-recall curve (if plot is true)\n",
    "    '''\n",
    "    \n",
    "    # calculate the precision-recall curve\n",
    "    Precision, Recall, Thresh = precision_recall_curve(true_probs, pred_probs)\n",
    "    Precision = np.fliplr([Precision])[0]  # so the array is increasing (you won't get negative AUC)\n",
    "    Recall = np.fliplr([Recall])[0]  # so the array is increasing (you won't get negative AUC)\n",
    "    AUPR = np.trapz(Precision, Recall)\n",
    "      \n",
    "    \n",
    "    # plot the precision-recall curve\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(Precision, Recall)\n",
    "        plt.title('Precision-Recall curve')\n",
    "        plt.xlabel('Precision')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.show()\n",
    "    \n",
    "    return AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6846088,
     "status": "ok",
     "timestamp": 1596193872229,
     "user": {
      "displayName": "Luna Maris",
      "photoUrl": "",
      "userId": "10626553832555274819"
     },
     "user_tz": -120
    },
    "id": "14ZvJ6cp2zT9",
    "outputId": "9e30b84a-1182-4f9b-fbae-8c458a4ba4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create placeholders\n",
      "Define the model for training\n",
      "[TL] InputLayer  input: (?, 512, 512, 3)\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_3: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_4: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 1 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "Define the model for testing\n",
      "[TL] InputLayer  input: (?, 512, 512, 3)\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_3: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d maxpool_4: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 1024 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] UpSampling2dLayer upsample2d_layer: is_scale: True size: (2, 2) method: 0 align_corners: False\n",
      "[TL] ConcatLayer concat_layer: axis: 3\n",
      "[TL] DropoutLayer dropout_layer: keep: 0.900000 is_fix: True\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d: n_filter: 1 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "Define outputs, losses and optimization\n",
      "calculating loss\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "calculating loss\n",
      "Setting up summary...\n",
      "Setting up Saver...\n",
      "[TL] WARNING: Function: `tensorlayer.layers.utils.initialize_global_variables` (in file: /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py:213: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "Initializing Batch Dataset Reader...\n",
      "Shape images: (324, 512, 512, 3)\n",
      "Shape annotations: (324, 512, 512, 1)\n",
      "Initializing Batch Dataset Reader...\n",
      "Shape images: (156, 512, 512, 3)\n",
      "Shape annotations: (156, 512, 512, 1)\n",
      "epoch 1 took 304.6539454460144s\n",
      "   train loss: 0.058477537340001655\n",
      "   train auc: 0.3917664567120662\n",
      "   train aupr: 0.008841894397302416\n",
      "   test loss: 0.12864714631667504\n",
      "   test auc: 0.49664578647863195\n",
      "   test aupr: 0.023877911534612162\n",
      "epoch 2 took 284.94244837760925s\n",
      "   train loss: 0.008114965022455348\n",
      "   train auc: 0.43407633525674355\n",
      "   train aupr: 0.009596188906832347\n",
      "   test loss: 0.1286471443107495\n",
      "   test auc: 0.5012171160788695\n",
      "   test aupr: 0.02506051652224596\n",
      "epoch 3 took 286.2344183921814s\n",
      "   train loss: 0.006625772006507894\n",
      "   train auc: 0.5758725437458633\n",
      "   train aupr: 0.015220009008603038\n",
      "   test loss: 0.1286471444540299\n",
      "   test auc: 0.5078380765001826\n",
      "   test aupr: 0.025830013879595434\n",
      "epoch 4 took 284.2374086380005s\n",
      "   train loss: 0.0062348109710944335\n",
      "   train auc: 0.6533778937322174\n",
      "   train aupr: 0.022217248699262032\n",
      "   test loss: 0.12864714488387108\n",
      "   test auc: 0.5013747209519678\n",
      "   test aupr: 0.02664487977928951\n",
      "epoch 5 took 284.81864523887634s\n",
      "   train loss: 0.006142964461037924\n",
      "   train auc: 0.6727966722002712\n",
      "   train aupr: 0.026839315988614883\n",
      "   test loss: 0.12864714545699266\n",
      "   test auc: 0.5077676323365328\n",
      "   test aupr: 0.02732497162436448\n",
      "epoch 6 took 283.0948660373688s\n",
      "   train loss: 0.005993365240067727\n",
      "   train auc: 0.6825428847970755\n",
      "   train aupr: 0.03591277041196458\n",
      "   test loss: 0.12864714631667504\n",
      "   test auc: 0.5064756606996842\n",
      "   test aupr: 0.026472612709372494\n",
      "epoch 7 took 283.41166853904724s\n",
      "   train loss: 0.0059505235565464115\n",
      "   train auc: 0.6995083782978659\n",
      "   train aupr: 0.04570618534609224\n",
      "   test loss: 0.1286471443107495\n",
      "   test auc: 0.5080466904489239\n",
      "   test aupr: 0.026359757506369756\n",
      "epoch 8 took 282.31661772727966s\n",
      "   train loss: 0.0061086604088174045\n",
      "   train auc: 0.7138523154939876\n",
      "   train aupr: 0.0492054027580981\n",
      "   test loss: 0.12864714588683385\n",
      "   test auc: 0.49714819626784124\n",
      "   test aupr: 0.026168877709363356\n",
      "epoch 9 took 282.1571137905121s\n",
      "   train loss: 0.005877849565068673\n",
      "   train auc: 0.7032906508700688\n",
      "   train aupr: 0.05036683156687949\n",
      "   test loss: 0.12864714502715147\n",
      "   test auc: 0.500264771409322\n",
      "   test aupr: 0.022840271525860673\n",
      "epoch 10 took 282.90139293670654s\n",
      "   train loss: 0.005846791889915174\n",
      "   train auc: 0.717344288729223\n",
      "   train aupr: 0.05761517413229129\n",
      "   test loss: 0.12864714302122593\n",
      "   test auc: 0.5024004770702841\n",
      "   test aupr: 0.028031110822632068\n",
      "epoch 11 took 283.7282609939575s\n",
      "   train loss: 0.005705853668688279\n",
      "   train auc: 0.7193961090313971\n",
      "   train aupr: 0.06016309679198229\n",
      "   test loss: 0.1286471444540299\n",
      "   test auc: 0.4883832161478305\n",
      "   test aupr: 0.024831579110077433\n",
      "epoch 12 took 283.69364047050476s\n",
      "   train loss: 0.005697326257143653\n",
      "   train auc: 0.7208475562839917\n",
      "   train aupr: 0.06246182429129126\n",
      "   test loss: 0.12864714631667504\n",
      "   test auc: 0.5013846770798801\n",
      "   test aupr: 0.029412241218922143\n",
      "epoch 13 took 282.63721776008606s\n",
      "   train loss: 0.0056968326039000036\n",
      "   train auc: 0.7200963371117945\n",
      "   train aupr: 0.061737691691780575\n",
      "   test loss: 0.12864714517043188\n",
      "   test auc: 0.5036235116125753\n",
      "   test aupr: 0.027881360904771706\n",
      "epoch 14 took 283.38618540763855s\n",
      "   train loss: 0.005664827726798615\n",
      "   train auc: 0.7304577018358716\n",
      "   train aupr: 0.06219342079886044\n",
      "   test loss: 0.12864714588683385\n",
      "   test auc: 0.5023192049281449\n",
      "   test aupr: 0.025018790297610952\n",
      "epoch 15 took 282.487911939621s\n",
      "   train loss: 0.005663420824998024\n",
      "   train auc: 0.7247522291624325\n",
      "   train aupr: 0.06227606557415883\n",
      "   test loss: 0.12864714545699266\n",
      "   test auc: 0.4997450686350154\n",
      "   test aupr: 0.02632009445679888\n",
      "epoch 16 took 282.65784883499146s\n",
      "   train loss: 0.005661047868973886\n",
      "   train auc: 0.7246117223301788\n",
      "   train aupr: 0.058821931006053596\n",
      "   test loss: 0.12864714574355346\n",
      "   test auc: 0.5071495021867908\n",
      "   test aupr: 0.027032617761086012\n",
      "epoch 17 took 281.9969525337219s\n",
      "   train loss: 0.005663649783215347\n",
      "   train auc: 0.7317352557312177\n",
      "   train aupr: 0.06441010049832814\n",
      "   test loss: 0.12864714502715147\n",
      "   test auc: 0.5008937913819366\n",
      "   test aupr: 0.024110327718455598\n",
      "epoch 18 took 279.31425309181213s\n",
      "   train loss: 0.005660915067117593\n",
      "   train auc: 0.7395807481492696\n",
      "   train aupr: 0.06180266841205109\n",
      "   test loss: 0.1286471444540299\n",
      "   test auc: 0.514076223836077\n",
      "   test aupr: 0.02780934956847231\n",
      "epoch 19 took 280.1643090248108s\n",
      "   train loss: 0.005661957867064134\n",
      "   train auc: 0.7138064226151156\n",
      "   train aupr: 0.06042160411771918\n",
      "   test loss: 0.12864714502715147\n",
      "   test auc: 0.5068060691992038\n",
      "   test aupr: 0.02406621666574133\n",
      "epoch 20 took 280.0131494998932s\n",
      "   train loss: 0.005662173532915336\n",
      "   train auc: 0.737619988339225\n",
      "   train aupr: 0.06343133002269682\n",
      "   test loss: 0.12864714459731028\n",
      "   test auc: 0.5018781512049466\n",
      "   test aupr: 0.027091534842790144\n",
      "epoch 20, the model has been saved successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.12864714459731028, 0.5018781512049466, 0.027091534842790144)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_network(train_images, train_annotations, test_images, test_annotations, loss_function = 'Sfce_loss', MAX_EPOCH = 20)\n",
    "# TrainImages, TrainAnnotations, TestImages, TestAnnotations, \n",
    "#                   Drop_Prob = 0.1, Init_Filters = 64, batch_size = 3, loss_function = 'UNet_loss', optim = 'Adam', \n",
    "#                   learning_rate = tf.Variable(1e-3, dtype=tf.float32), MAX_EPOCH = 10, SaveResults = True"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNet_sigmoid_Training.ipynb",
   "provenance": [
    {
     "file_id": "1QMAMVVMbSl6bTe6A09aprdmgYrNBEcrI",
     "timestamp": 1596124792763
    },
    {
     "file_id": "1cPo0a7rxvx8xVA1rLbdlTcdllub8HVn5",
     "timestamp": 1596020580331
    },
    {
     "file_id": "1N09tXe6iDGW9tt3_cWA_K-sYrT1Q98qq",
     "timestamp": 1596016036593
    },
    {
     "file_id": "1pvSj2cOo177dqWp1y6lbiwohGTGeGVm1",
     "timestamp": 1596012829809
    },
    {
     "file_id": "1ko8HCMMTNlaR1MCC-1f6QL1uAaqzHXwO",
     "timestamp": 1595928299309
    },
    {
     "file_id": "1cjKN36peUbhC36sgbu1cp5rwTPmzAtcg",
     "timestamp": 1595852695030
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
