Hyperparameter combination: 
learn rate 0.001, batch size 6, dropout 0.1, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 25 
AUC: mean: 0.5090311169624329, standard deviation: 0.007776081562042236 
AUPR: mean: 0.5375552177429199, standard deviation: 0.08415964245796204 
Loss: mean: 0.512925922870636, standard deviation: 0.5625014305114746 
training time per epoch: mean: 81.48491946856181 
 
Hyperparameter combination: 
learn rate 0.001, batch size 6, dropout 0.1, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 25 
AUC: mean: 0.4909694194793701, standard deviation: 0.00995014887303114 
AUPR: mean: 0.5094452500343323, standard deviation: 0.031054167076945305 
Loss: mean: 0.11582192033529282, standard deviation: 0.00027352021425031126 
training time per epoch: mean: 41.85506375630697 
 
Hyperparameter combination: 
learn rate 0.001, batch size 6, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 25 
AUC: mean: 0.5106127858161926, standard deviation: 0.015008745715022087 
AUPR: mean: 0.52000492811203, standard deviation: 0.026863154023885727 
Loss: mean: 0.9032723903656006, standard deviation: 0.5570987462997437 
training time per epoch: mean: 81.44650936126709 
 
Hyperparameter combination: 
learn rate 0.001, batch size 6, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 25 
AUC: mean: 0.5173659920692444, standard deviation: 0.012259814888238907 
AUPR: mean: 0.5513474345207214, standard deviation: 0.05279913917183876 
Loss: mean: 0.1155702993273735, standard deviation: 0.000618997379206121 
training time per epoch: mean: 41.80748756726583 
 
Hyperparameter combination: 
learn rate 0.001, batch size 12, dropout 0.1, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 25 
AUC: mean: 0.49559175968170166, standard deviation: 0.006234193220734596 
AUPR: mean: 0.5134686827659607, standard deviation: 0.06286796182394028 
Loss: mean: 0.4404807984828949, standard deviation: 0.2709735929965973 
training time per epoch: mean: 69.60504166285197 
 
Hyperparameter combination: 
learn rate 0.001, batch size 12, dropout 0.1, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 25 
AUC: mean: 0.5450063347816467, standard deviation: 0.047440558671951294 
AUPR: mean: 0.5630111694335938, standard deviation: 0.052870847284793854 
Loss: mean: 0.05778248608112335, standard deviation: 0.00010155377822229639 
training time per epoch: mean: 38.66372092564901 
 
Hyperparameter combination: 
learn rate 0.001, batch size 12, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 25 
AUC: mean: 0.5080743432044983, standard deviation: 0.005731040146201849 
AUPR: mean: 0.525384247303009, standard deviation: 0.05218334123492241 
Loss: mean: 0.27247264981269836, standard deviation: 0.26289838552474976 
training time per epoch: mean: 70.32396101951599 
 
Hyperparameter combination: 
learn rate 0.001, batch size 12, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 25 
AUC: mean: 0.5007948875427246, standard deviation: 0.013418729417026043 
AUPR: mean: 0.5335384011268616, standard deviation: 0.03297857195138931 
Loss: mean: 0.057949792593717575, standard deviation: 0.0003549757821019739 
training time per epoch: mean: 38.91310636202494 
 
Hyperparameter combination: 
learn rate 1e-05, batch size 6, dropout 0.1, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 25 
AUC: mean: 0.5234499573707581, standard deviation: 0.015556556172668934 
AUPR: mean: 0.5303965210914612, standard deviation: 0.029739713296294212 
Loss: mean: 0.11560744047164917, standard deviation: 0.00012936563871335238 
training time per epoch: mean: 83.74277726809184 
 
Hyperparameter combination: 
learn rate 1e-05, batch size 6, dropout 0.1, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 25 
AUC: mean: 0.5431233644485474, standard deviation: 0.009809988550841808 
AUPR: mean: 0.5469359755516052, standard deviation: 0.03999051824212074 
Loss: mean: 0.11573118716478348, standard deviation: 0.0003305151767563075 
training time per epoch: mean: 41.801214933395386 
 
Hyperparameter combination: 
learn rate 1e-05, batch size 6, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 25 
AUC: mean: 0.5281451344490051, standard deviation: 0.01760253496468067 
AUPR: mean: 0.5362873673439026, standard deviation: 0.030306372791528702 
Loss: mean: 0.11544951051473618, standard deviation: 0.0001700255088508129 
training time per epoch: mean: 83.86997350056966 
 
Hyperparameter combination: 
learn rate 1e-05, batch size 6, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 25 
AUC: mean: 0.5302107334136963, standard deviation: 0.019601112231612206 
AUPR: mean: 0.5507567524909973, standard deviation: 0.030308421701192856 
Loss: mean: 0.11574634164571762, standard deviation: 0.0003141440683975816 
training time per epoch: mean: 41.834275325139366 
 
Hyperparameter combination: 
learn rate 1e-05, batch size 12, dropout 0.1, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 25 
AUC: mean: 0.5446513891220093, standard deviation: 0.014430273324251175 
AUPR: mean: 0.5503048300743103, standard deviation: 0.03407931327819824 
Loss: mean: 0.057836875319480896, standard deviation: 8.304374205181375e-05 
training time per epoch: mean: 71.4265722433726 
 
Hyperparameter combination: 
learn rate 1e-05, batch size 12, dropout 0.1, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 25 
AUC: mean: 0.5321879982948303, standard deviation: 0.026890702545642853 
AUPR: mean: 0.5310797095298767, standard deviation: 0.03940201550722122 
Loss: mean: 0.05774928629398346, standard deviation: 0.00011353011359460652 
training time per epoch: mean: 39.155868450800575 
 
Hyperparameter combination: 
learn rate 1e-05, batch size 12, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 25 
AUC: mean: 0.5438034534454346, standard deviation: 0.015905633568763733 
AUPR: mean: 0.5469141602516174, standard deviation: 0.03935616835951805 
Loss: mean: 0.05783255398273468, standard deviation: 0.0001432642457075417 
training time per epoch: mean: 71.3014833132426 
 
Hyperparameter combination: 
learn rate 1e-05, batch size 12, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 25 
AUC: mean: 0.5327783226966858, standard deviation: 0.02160600759088993 
AUPR: mean: 0.5351278781890869, standard deviation: 0.021779483184218407 
Loss: mean: 0.05775689706206322, standard deviation: 0.00010683797881938517 
training time per epoch: mean: 39.32376519838969 
 
