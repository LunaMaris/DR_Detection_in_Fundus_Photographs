{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GPU-ResNet18_GridSearch.ipynb","provenance":[{"file_id":"1TaBLRFkUx5mmEC88Nu_2dBDirOuVgB8W","timestamp":1596525719640},{"file_id":"1pvSj2cOo177dqWp1y6lbiwohGTGeGVm1","timestamp":1596123685910},{"file_id":"1ko8HCMMTNlaR1MCC-1f6QL1uAaqzHXwO","timestamp":1595928299309},{"file_id":"1cjKN36peUbhC36sgbu1cp5rwTPmzAtcg","timestamp":1595852695030}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"9eyAksxJOFsi","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597750226843,"user_tz":-120,"elapsed":2747,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}},"outputId":"786afae1-5323-4201-dfe4-09f538a7369d"},"source":["# import necessary libraries\n","\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.model_selection import train_test_split\n","\n","import time\n","\n","print(tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wIRkU8aWXO0R","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597750228262,"user_tz":-120,"elapsed":4156,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}},"outputId":"bb5a079d-caf3-4858-d64a-4b9802592147"},"source":["# define how many gpus are available and set a memmory limit\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","print(\"Number of GPUs Available: \", len(gpus))\n","for i in range(len(gpus)):\n","    tf.config.experimental.set_virtual_device_configuration(gpus[i], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7900)]) "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Number of GPUs Available:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VG-6e60Mxwmv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1597750232522,"user_tz":-120,"elapsed":8412,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}},"outputId":"ced134e4-34a1-419a-ca66-dd8b5bd73d88"},"source":["strategy = tf.distribute.MirroredStrategy()\n","# the number of replicas that is created by the strategy should be equal to the number of GPU's available\n","print ('Number of synchronized replicas created: {}'.format(strategy.num_replicas_in_sync))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","Number of synchronized replicas created: 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y9BMq9Q_svYm","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1597750365174,"user_tz":-120,"elapsed":141054,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}},"outputId":"c1c69ccc-7a97-4d8e-97c8-b68757ef0ba7"},"source":["# read in train and test data in case Google DRIVE is used\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x4SbTTqBltfN","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1597750456285,"user_tz":-120,"elapsed":232157,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}},"outputId":"01fc4736-d044-4b84-8da4-f14ccaf9106b"},"source":["# Basepath for Google DRIVE:\n","Basepath = '/content/drive/My Drive/Stage_ENT_Studios_2/Data/Kaggle/Arrays_5GB_float32/'\n","\n","# Basepath for Jupyter notebooks:\n","# Basepath = 'C:/Users/lunam/Documents/1steMaster/Stage/Data_FinalArrays/Kaggle/Array_10GB/'\n","# also a version with 5GB and 20GB\n","\n","# Basepath for KILI\n","# Basepath = '/home/kili/Desktop/Data_FinalArrays/Kaggle/Arrays/'\n","\n","# train data\n","train_images = np.load(Basepath + 'train_images_Final.npy')\n","print('Shape train images: {}'.format(train_images.shape))\n","\n","train_labels =  np.load(Basepath + 'train_labels_Final.npy')\n","print('Shape train labels: {}'.format(train_labels.shape))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Shape train images: (702, 512, 512, 3)\n","Shape train labels: (702, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DVa4yn4lltfc","colab":{},"executionInfo":{"status":"ok","timestamp":1597750456289,"user_tz":-120,"elapsed":232157,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["# direction where the results of the GridSearch will be stored\n","\n","# direction for Google DRIVE\n","dir_gridsearch = '/content/drive/My Drive/Stage_ENT_Studios_2/DR_Grading/ResNet18/GridSearchResults/GridSearch_ResNet18.txt'\n","\n","# direction for jupyter notebooks\n","# dir_gridsearch = 'C:/Users/lunam/Documents/1steMaster/Stage/Code_Final/DR_classification/DeepLearningClassification/ResNet18_GPU/GridSearchResults/Gridsearch_ResNet18.txt'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FICWJHVxltfh","colab":{},"executionInfo":{"status":"ok","timestamp":1597750456290,"user_tz":-120,"elapsed":232155,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["def Identity_Block(Input_Image, n_filters, dropout_prob = 0):\n","\n","\n","    # initialization of the weights\n","    W_init = tf.initializers.GlorotUniform()\n","    \n","    # Shortcut path: Identity function\n","    Shortcut_Image = Input_Image\n","    \n","    # Main path, Main_Image represents the image that is passed through different layers\n","    Main_Image = Input_Image\n","\n","    Main_Image = tf.keras.layers.Conv2D(n_filters, (3,3), kernel_initializer= W_init, padding = 'same')(Main_Image) # padding is needed to keep the same dimensions\n","    Main_Image = tf.keras.layers.BatchNormalization(axis = 1)(Main_Image)\n","    Main_Image = tf.nn.relu(Main_Image)\n","\n","    Main_Image = tf.keras.layers.Conv2D(n_filters, (3,3), kernel_initializer= W_init, padding = 'same')(Main_Image)\n","    \n","    # Output: Relu activation from (Shortcut path + Main path)\n","    Output_Image = tf.keras.layers.Add()([Main_Image, Shortcut_Image])\n","\n","    if dropout_prob != 0:\n","        Output_Image = tf.keras.layers.Dropout(rate = dropout_prob)(Output_Image)\n","\n","    Output_Image = tf.nn.relu(Output_Image)\n","    \n","    return Output_Image"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WLiJSbDMSfcX","colab":{},"executionInfo":{"status":"ok","timestamp":1597750456291,"user_tz":-120,"elapsed":232153,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["def Convolutional_Block(Input_Image, n_filters, dropout_prob = 0, pooling = False):\n","    \n","\n","    # initialization of the weights\n","    W_init = tf.initializers.GlorotUniform()\n","\n","    # Shortcut path\n","    Shortcut_Image = Input_Image\n","    Shortcut_Image = tf.keras.layers.Conv2D(n_filters, (3,3), strides = (2,2), kernel_initializer= W_init)(Shortcut_Image) # stride leads to a reduction in size\n","    Shortcut_Image = tf.keras.layers.BatchNormalization(axis = 1)(Shortcut_Image)\n","\n","    # Main path\n","    Main_Image = Input_Image\n","    \n","    Main_Image = tf.keras.layers.Conv2D(n_filters, (3,3), strides = (2,2), kernel_initializer= W_init)(Main_Image)\n","    Main_Image = tf.keras.layers.BatchNormalization(axis = 1)(Main_Image)\n","    Main_Image = tf.nn.relu(Main_Image)\n","\n","    Main_Image = tf.keras.layers.Conv2D(n_filters, (3,3), kernel_initializer= W_init, padding = 'same')(Main_Image) # padding is needed to keep the same dimensions\n","    Main_Image = tf.keras.layers.BatchNormalization(axis = 1)(Main_Image)\n","\n","\n","    # Output: Relu activation from (Shortcut path + Main path)\n","    Output_Image = tf.keras.layers.Add()([Main_Image, Shortcut_Image])\n","\n","    if pooling:\n","        Output_Image = tf.keras.layers.MaxPool2D((2,2))(Output_Image)\n","\n","    if dropout_prob != 0:\n","        Output_Image = tf.keras.layers.Dropout(rate = dropout_prob)(Output_Image)\n","\n","    Output_Image = tf.nn.relu(Output_Image)\n","    \n","    return Output_Image"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WHvLi07XShxm","colab":{},"executionInfo":{"status":"ok","timestamp":1597750456292,"user_tz":-120,"elapsed":232152,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["def ResNet18(init_filters = 64, drop_prob = 0.1, dense_nodes = 1000, ExtraPooling = False):\n","    '''This function defines the original ResNet18 network'''\n","    \n","    # initialization of the weights\n","    W_init = tf.initializers.GlorotUniform()\n","    \n","    # Input\n","    X_Input = tf.keras.layers.Input(shape = (256,256, 3))\n","    \n","    # Convolutional layer 1\n","    X = tf.keras.layers.ZeroPadding2D((3, 3))(X_Input)\n","    X = tf.keras.layers.Conv2D(init_filters, (7,7), strides=(2, 2), kernel_initializer= W_init)(X)\n","    X = tf.keras.layers.BatchNormalization(axis = 1)(X)\n","    X = tf.nn.relu(X)\n","    \n","    # Convolutional layer 2\n","    X = tf.keras.layers.ZeroPadding2D((1, 1))(X)\n","    X = tf.keras.layers.MaxPool2D((3,3), strides = (2,2))(X)\n","    X = Identity_Block(X, init_filters, dropout_prob = drop_prob)\n","    X = Identity_Block(X, init_filters, dropout_prob = 0)\n","\n","    # Convolutional layer 3\n","    X = tf.keras.layers.ZeroPadding2D((1, 1))(X)\n","    X = Convolutional_Block(X, 2* init_filters, dropout_prob = drop_prob, pooling = ExtraPooling)\n","    X = Identity_Block(X, 2* init_filters, dropout_prob = 0)\n","\n","    # Convolutional layer 4\n","    X = tf.keras.layers.ZeroPadding2D((1, 1))(X)\n","    X = Convolutional_Block(X,  4* init_filters, dropout_prob = drop_prob, pooling = ExtraPooling)\n","    X = Identity_Block(X, 4* init_filters, dropout_prob = 0)\n","\n","    # Convolutional layer 5\n","    X = tf.keras.layers.ZeroPadding2D((1, 1))(X)\n","    X = Convolutional_Block(X, 8* init_filters, dropout_prob = drop_prob)\n","    X = Identity_Block(X, 8* init_filters, dropout_prob = 0)\n","\n","    # Output layer\n","    X = tf.keras.layers.AveragePooling2D((2,2))(X)\n","    X = tf.keras.layers.Flatten()(X)\n","    X = tf.keras.layers.Dense(dense_nodes, activation= tf.nn.relu)(X)\n","    X_Output = tf.keras.layers.Dense(2, activation= tf.nn.softmax)(X) # dense layer where the chance on benign and malignant is represented\n","\n","    # define the model\n","    model = tf.keras.Model(inputs = X_Input, outputs = X_Output)\n","      \n","    return model"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uXe-N1A0JgM5","colab":{},"executionInfo":{"status":"ok","timestamp":1597750456292,"user_tz":-120,"elapsed":232149,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["# loss function\n","def Bin_CrossEntropy_Loss(pred_labels, true_labels, GlobalBatchSize):\n","\n","    true_labels_pos = true_labels[:,0]\n","    pred_labels_pos = pred_labels[:,0]\n","\n","    loss_object = tf.keras.losses.BinaryCrossentropy(reduction= tf.keras.losses.Reduction.NONE)\n","    loss = loss_object([true_labels_pos], [pred_labels_pos])[0]\n","    return (loss/ GlobalBatchSize)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VQg7qWs9Wo9r","colab":{},"executionInfo":{"status":"ok","timestamp":1597750456489,"user_tz":-120,"elapsed":232343,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["def train_network(TrainImages, TrainLabels, TestImages, TestLabels, \n","                  Drop_Prob = 0.1, Init_Filters = 64, Dense_Nodes = 1000, extra_pooling = False, batch_size = 3, loss_function = 'BinCrossEntr', optim = 'Adam', \n","                  learning_rate = tf.Variable(1e-5, dtype=tf.float32), MAX_EPOCH = 10, SaveResults = True):\n","    '''\n","    This function trains the UNet on the indicated train data with corresponding annotations\n","    At the end the trained model is being saved\n","    '''\n","\n","    # define the train and test batches that can be fed into the network\n","    # global batch size defines the batch size over all availabel GPU's\n","    print('Creating distributed data')\n","    Global_batch_size = batch_size * strategy.num_replicas_in_sync\n","    train_batch_data  = tf.data.Dataset.from_tensor_slices((TrainImages, TrainLabels)).shuffle(TrainImages.shape[0]).batch(Global_batch_size) \n","    test_batch_data = tf.data.Dataset.from_tensor_slices((TestImages, TestLabels)).batch(Global_batch_size) \n","\n","    # distribute the data over the different GPU's\n","    train_dist_data =  strategy.experimental_distribute_dataset(train_batch_data)\n","    test_dist_data =  strategy.experimental_distribute_dataset(test_batch_data)\n","\n","    # define the model that will be used for training and for testing\n","    # the model, optimisation and loss have to be distributed among GPU's\n","    tf.compat.v1.reset_default_graph()\n","    with strategy.scope():\n","\n","        # model\n","        print('Defining the model')\n","        model = ResNet18(init_filters = Init_Filters, drop_prob = Drop_Prob, dense_nodes= Dense_Nodes, ExtraPooling= extra_pooling)\n","        \n","        # loss\n","        print('Defining loss')\n","        def compute_loss(PredictedLabels, TrueLabels):\n","            if loss_function == 'BinCrossEntr':\n","                loss = Bin_CrossEntropy_Loss(PredictedLabels, TrueLabels, Global_batch_size)\n","            return loss\n","\n","        # optimization\n","        steps_per_epoch = int(TrainImages.shape[0]/Global_batch_size)\n","        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate= learning_rate, decay_steps= MAX_EPOCH*steps_per_epoch*0.25, decay_rate=0.2, staircase = True)\n","        print('Defining optimization')\n","        if optim == 'Adam':\n","            train_op = tf.keras.optimizers.Adam(learning_rate = lr_schedule)\n","        elif optim == 'sgd':\n","            train_op = tf.keras.optimizers.SGD(learning_rate = lr_schedule)\n","\n","        # defining the metrics\n","        print('Defining the metrics')\n","        test_roc_auc = tf.keras.metrics.AUC(curve = 'ROC')\n","        test_pr_auc = tf.keras.metrics.AUC(curve = 'PR')\n","\n","    # one train step is a step in which one batch of data is fed to every GPU\n","    def Train_Step(input):\n","\n","        with tf.GradientTape() as tape:\n","            train_images_batch, train_labels_batch = input\n","            # make prediction with model\n","            pred_train_labels = model(train_images_batch, training = True)\n","            # compute loss\n","            train_err = compute_loss(pred_train_labels, train_labels_batch)\n","            \n","        # update model\n","        train_weights = model.trainable_variables\n","        gradients = tape.gradient(train_err, train_weights)\n","        train_op.apply_gradients(zip(gradients, train_weights))\n","\n","    # for the last epoch some testing has to be done, in a test step one batch of test data is fed to every GPU\n","    def Test_Step(input):\n","        test_images_batch, test_labels_batch = input\n","\n","        # make prediction with model\n","        pred_test_labels = model(test_images_batch, training = False)\n","        # compute loss\n","        test_err = compute_loss(pred_test_labels, test_labels_batch)\n","        \n","        # compute auc and aupr score\n","        temp_test_labels = test_labels_batch[:,0]\n","        temp_test_pred_labels = pred_test_labels[:,0]\n","        test_roc_auc.update_state(temp_test_labels, temp_test_pred_labels)\n","        test_pr_auc.update_state(temp_test_labels, temp_test_pred_labels)\n","\n","        # the error per replica is returned\n","        return test_err, test_roc_auc.result(), test_pr_auc.result()\n","\n","    @tf.function\n","    def distributed_train_step(dataset_inputs):\n","        strategy.run(Train_Step, args=(dataset_inputs,))\n","\n","\n","    @tf.function\n","    def distributed_test_step(dataset_inputs):\n","        per_replica_losses, per_replica_roc_auc, per_replica_pr_auc = strategy.run(Test_Step, args=(dataset_inputs,))\n","        return per_replica_losses, per_replica_roc_auc, per_replica_pr_auc\n","\n","\n","    # the train and test steps now have to be performed with the distributed strategy\n","    print('Training')\n","    for epo in range(1,MAX_EPOCH+1):\n","        \n","        # go over all global batches\n","        for train_input_data in train_dist_data:\n","            distributed_train_step(train_input_data)\n","\n","        # some testing has to be done at the last epoch\n","        if epo == MAX_EPOCH:\n","            print('Testing')\n","            n_test_steps = 0\n","            total_test_loss = 0\n","            total_test_auc = 0\n","            total_test_aupr = 0\n","            for test_input_data in test_dist_data:\n","                n_test_steps+=1\n","                per_replica_test_losses, per_replica_test_roc_auc, per_replica_test_pr_auc = distributed_test_step(test_input_data)\n","                total_test_loss += strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_test_losses, axis=None)\n","                total_test_auc += strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_test_roc_auc, axis=None)\n","                total_test_aupr += strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_test_pr_auc, axis=None)\n","\n","            total_test_loss = total_test_loss/n_test_steps\n","            total_test_auc = total_test_auc/n_test_steps\n","            total_test_aupr = total_test_aupr/n_test_steps   \n","\n","    return total_test_loss, total_test_auc, total_test_aupr   "],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eog-QtTMmSu4"},"source":["The functions beneith can be used to perform a gridsearch over different combinations of parameters to define the parametercombination that gives the best results in terms of performance and training time."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3-Cb8VYnltf4","colab":{},"executionInfo":{"status":"ok","timestamp":1597750456490,"user_tz":-120,"elapsed":232342,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["# gridsearch: look for the most optimal hyperparameters, making use of cross-validation\n","\n","# for this a separate validation set has to be defined\n","# three fold cross-validation is performed in this case\n","def ThreeFoldSplit(n_split):\n","    '''\n","    This function calculates a three-fold split of the train_images and train_annotations\n","    Depending on n_split another train and validation set is defined\n","    '''\n","    \n","    a = train_images.shape[0]\n","    b = int(a/3)\n","    \n","    val_images = train_images[n_split*b:(n_split+1)*b]\n","    val_labels = train_labels[n_split*b:(n_split+1)*b]\n","    \n","    # split the train set in to three parts\n","    if n_split == 0:\n","        tr_images = train_images[b:]\n","        tr_labels = train_labels[b:]\n","        \n","    if n_split == 1:\n","        tr_images = np.vstack((train_images[0:b], train_images[2*b:]))\n","        tr_labels = np.vstack((train_labels[0:b], train_labels[2*b:]))\n","        \n","    if n_split == 2:\n","        tr_images = train_images[0:2*b]\n","        tr_labels = train_labels[0:2*b]\n","    \n","    return tr_images, tr_labels, val_images, val_labels"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sQbJLfkFltf7","colab":{},"executionInfo":{"status":"ok","timestamp":1597750731518,"user_tz":-120,"elapsed":482,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["# function to choose the best hyperparameter combination based on model performance in terms of the ROC AUC score\n","def Hyperparam_Optimization(lr_list, Batch_Size_list, dropout_list, Dense_Nodes_list, MaxPool_list, optim_list, \n","                            init_filters_list, epochs_list, savefile):\n","\n","    n = 0\n","    file = open(savefile,'w') \n","    start = time.time()\n","    for LearnRate in lr_list:\n","        for BatchSize in Batch_Size_list:\n","            for Dropout in dropout_list:\n","                for DenseNodes in Dense_Nodes_list:\n","                    for MaxPool in MaxPool_list:\n","                        for Optim in optim_list:\n","                            for InitFilters in init_filters_list:\n","                                for Epoch in epochs_list:\n","                                \n","                                    n +=1\n","                                    print('Evaluating parameter combination {} ...'.format(n))\n","                                        \n","                                    AUC_list = []\n","                                    AUPR_list = []\n","                                    Loss_list = []\n","                                    time_list = []\n","                                    # 3-fold cross-validation is used to evaluate the model \n","                                    # for a certain param combination \n","                                    for fold in range(3):\n","                                            \n","                                        tr_images, tr_labels, val_images, val_labels = ThreeFoldSplit(fold)\n","                                        \n","                                        # fitting the model to the data for a certain fold and defining the auc, aupr and loss\n","                                        # these values can later on be compared for different param combinations\n","                                        start_time = time.time()\n","                                        \n","                                        val_loss, val_auc, val_aupr = train_network(tr_images, tr_labels, val_images, val_labels, Drop_Prob = Dropout, Init_Filters = InitFilters, \n","                                                                                    Dense_Nodes = DenseNodes, extra_pooling = MaxPool, batch_size = BatchSize, optim = Optim, \n","                                                                                    learning_rate = tf.Variable(LearnRate, dtype=tf.float32), MAX_EPOCH = Epoch, SaveResults = False)\n","                                        \n","                                        end_time = time.time()\n","                                            \n","                                        # creat a 1D numpy array with the predicted and true outputs   \n","                                        AUC_list.append(val_auc)\n","                                        AUPR_list.append(val_aupr)\n","                                        Loss_list.append(val_loss) \n","                                        time_list.append(end_time-start_time) \n","                                        \n","                                    # calculate the mean and standard-dev of the AUC, AUPR, loss and time for all three folds\n","                                    mean_AUC = np.mean(np.array(AUC_list), axis = 0)\n","                                    std_AUC = np.std(np.array(AUC_list), axis = 0)\n","                                    mean_AUPR = np.mean(np.array(AUPR_list), axis = 0)\n","                                    std_AUPR = np.std(np.array(AUPR_list), axis = 0)\n","                                    mean_Loss = np.mean(np.array(Loss_list), axis = 0)\n","                                    std_Loss = np.std(np.array(Loss_list), axis = 0)\n","                                    mean_time = np.mean(time_list, axis = 0)\n","                                        \n","                                    # print out these values together with the training time for this parameter set\n","                                    print('Hyperparameter combination:')\n","                                    print('learn rate {}, batch size {}, dropout {}, dense nodes {}, maxpooling {}, optimization {}, initial filters {} and epochs {}'.format(LearnRate, BatchSize, Dropout, DenseNodes, MaxPool, Optim, InitFilters, Epoch))\n","                                    print('Results:')\n","                                    print('AUC: mean: {}, standard deviation: {}'.format(mean_AUC, std_AUC))\n","                                    print('AUPR: mean: {}, standard deviation: {}'.format(mean_AUPR, std_AUPR)) \n","                                    print('Loss: mean: {}, standard deviation: {}'.format(mean_Loss, std_Loss)) \n","                                    print('training time per epoch: mean: {}'.format(mean_time))\n","\n","                                    # save all values in a txt file\n","                                    file.write('Hyperparameter combination: \\n')\n","                                    file.write('learn rate {}, batch size {}, dropout {}, dense nodes {}, maxpooling {}, optimization {}, initial filters {} and epochs {} \\n'.format(LearnRate, BatchSize, Dropout, DenseNodes, MaxPool, Optim, InitFilters, Epoch))\n","                                    file.write('AUC: mean: {}, standard deviation: {} \\n'.format(mean_AUC, std_AUC))\n","                                    file.write('AUPR: mean: {}, standard deviation: {} \\n'.format(mean_AUPR, std_AUPR))\n","                                    file.write('Loss: mean: {}, standard deviation: {} \\n'.format(mean_Loss, std_Loss))\n","                                    file.write('training time per epoch: mean: {} \\n'.format(mean_time))\n","                                    file.write(' \\n')\n","    print('The gridsearch took {}s'.format(time.time()- start))\n","    file.close()                                                           "],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kL85YGBWltf-","colab":{},"executionInfo":{"status":"ok","timestamp":1597750456492,"user_tz":-120,"elapsed":232339,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}}},"source":["# # different options that have to be tried\n","# # learn rat\n","# LR_list = [1e-5, 1e-6]\n","# # batch size\n","# BS_list = [3, 6]\n","# # drop probab\n","# DP_list = [0.3, 0.5]\n","# # amount of dense nodes at the end\n","# DN_list = [1000, 100]\n","# # extra maxpooling or not\n","# EMP_list = [True, False]\n","# # optimisation function\n","# OF_list = ['Adam', 'sgd']\n","# # initial amount of filters\n","# IF_list = [64, 32]\n","# # amount of epochs\n","# EP_list = [10,30]\n","# # alpha and gamma, parameters of the focal loss function\n","\n","# Hyperparam_Optimization(lr_list = LR_list, Batch_Size_list = BS_list, dropout_list = DP_list, \n","#                         Dense_Nodes_list = DN_list, MaxPool_list = EMP_list, optim_list = OF_list, init_filters_list = IF_list, \n","#                         epochs_list = EP_list, savefile = dir_gridsearch)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"clpDVDKl1GO9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1597751402512,"user_tz":-120,"elapsed":559072,"user":{"displayName":"Luna Maris","photoUrl":"","userId":"08986518200734496308"}},"outputId":"ab01ebd0-ff79-427e-b562-32e22607690d"},"source":["# different options that have to be tried\n","# learn rat\n","LR_list = [1e-3, 1e-5]\n","# batch size\n","BS_list = [6,12,24]\n","# drop probab\n","DP_list = [0.3, 0.5]\n","# amount of dense nodes at the end\n","DN_list = [1000, 100]\n","# extra maxpooling or not\n","EMP_list = [True, False]\n","# optimisation function\n","OF_list = ['Adam']\n","# initial amount of filters\n","IF_list = [64, 32]\n","# amount of epochs\n","EP_list = [1]\n","# alpha and gamma, parameters of the focal loss function\n","\n","Hyperparam_Optimization(lr_list = LR_list, Batch_Size_list = BS_list, dropout_list = DP_list, \n","                        Dense_Nodes_list = DN_list, MaxPool_list = EMP_list, optim_list = OF_list, init_filters_list = IF_list, \n","                        epochs_list = EP_list, savefile = dir_gridsearch)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Evaluating parameter combination 1 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 1\n","Results:\n","AUC: mean: 0.4702993929386139, standard deviation: 0.04200298711657524\n","AUPR: mean: 0.4548572301864624, standard deviation: 0.029058728367090225\n","Loss: mean: 1.8524786233901978, standard deviation: 1.1383150815963745\n","training time per epoch: mean: 15.183771133422852\n","Evaluating parameter combination 2 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 1\n","Results:\n","AUC: mean: 0.4785609245300293, standard deviation: 0.061799950897693634\n","AUPR: mean: 0.44498181343078613, standard deviation: 0.01770632527768612\n","Loss: mean: 0.6471459865570068, standard deviation: 0.4467085599899292\n","training time per epoch: mean: 10.30384866396586\n","Evaluating parameter combination 3 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 1000, maxpooling False, optimization Adam, initial filters 64 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 1000, maxpooling False, optimization Adam, initial filters 64 and epochs 1\n","Results:\n","AUC: mean: 0.48234128952026367, standard deviation: 0.016178440302610397\n","AUPR: mean: 0.4622388780117035, standard deviation: 0.034060895442962646\n","Loss: mean: 2.2759783267974854, standard deviation: 0.1870531141757965\n","training time per epoch: mean: 14.583484172821045\n","Evaluating parameter combination 4 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 1000, maxpooling False, optimization Adam, initial filters 32 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 1000, maxpooling False, optimization Adam, initial filters 32 and epochs 1\n","Results:\n","AUC: mean: 0.49537038803100586, standard deviation: 0.006547288503497839\n","AUPR: mean: 0.4693988263607025, standard deviation: 0.024373149499297142\n","Loss: mean: 2.586693525314331, standard deviation: 0.3527125120162964\n","training time per epoch: mean: 10.546968619028727\n","Evaluating parameter combination 5 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 100, maxpooling True, optimization Adam, initial filters 64 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 100, maxpooling True, optimization Adam, initial filters 64 and epochs 1\n","Results:\n","AUC: mean: 0.5055508017539978, standard deviation: 0.009762721136212349\n","AUPR: mean: 0.4859232008457184, standard deviation: 0.007139406632632017\n","Loss: mean: 1.1292387247085571, standard deviation: 0.7406100034713745\n","training time per epoch: mean: 11.878894011179606\n","Evaluating parameter combination 6 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 100, maxpooling True, optimization Adam, initial filters 32 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 100, maxpooling True, optimization Adam, initial filters 32 and epochs 1\n","Results:\n","AUC: mean: 0.45101070404052734, standard deviation: 0.045952122658491135\n","AUPR: mean: 0.43697062134742737, standard deviation: 0.049915775656700134\n","Loss: mean: 0.5922743678092957, standard deviation: 0.2857256233692169\n","training time per epoch: mean: 10.352965037027994\n","Evaluating parameter combination 7 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 100, maxpooling False, optimization Adam, initial filters 64 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 100, maxpooling False, optimization Adam, initial filters 64 and epochs 1\n","Results:\n","AUC: mean: 0.49537038803100586, standard deviation: 0.006547288503497839\n","AUPR: mean: 0.4693988263607025, standard deviation: 0.024373149499297142\n","Loss: mean: 2.8293943405151367, standard deviation: 0.222798153758049\n","training time per epoch: mean: 13.717444658279419\n","Evaluating parameter combination 8 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 100, maxpooling False, optimization Adam, initial filters 32 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.3, dense nodes 100, maxpooling False, optimization Adam, initial filters 32 and epochs 1\n","Results:\n","AUC: mean: 0.49537038803100586, standard deviation: 0.006547288503497839\n","AUPR: mean: 0.4693988263607025, standard deviation: 0.024373149499297142\n","Loss: mean: 2.586693525314331, standard deviation: 0.3527125120162964\n","training time per epoch: mean: 9.489077806472778\n","Evaluating parameter combination 9 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 1000, maxpooling True, optimization Adam, initial filters 64 and epochs 1\n","Results:\n","AUC: mean: 0.5104696154594421, standard deviation: 0.0252714604139328\n","AUPR: mean: 0.4756368398666382, standard deviation: 0.031650055199861526\n","Loss: mean: 1.7929754257202148, standard deviation: 0.8588666915893555\n","training time per epoch: mean: 13.150847991307577\n","Evaluating parameter combination 10 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 1000, maxpooling True, optimization Adam, initial filters 32 and epochs 1\n","Results:\n","AUC: mean: 0.534331738948822, standard deviation: 0.024969620630145073\n","AUPR: mean: 0.49256229400634766, standard deviation: 0.03941621258854866\n","Loss: mean: 0.9097345471382141, standard deviation: 0.9058263301849365\n","training time per epoch: mean: 10.47945245107015\n","Evaluating parameter combination 11 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 1000, maxpooling False, optimization Adam, initial filters 64 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 1000, maxpooling False, optimization Adam, initial filters 64 and epochs 1\n","Results:\n","AUC: mean: 0.49537038803100586, standard deviation: 0.006547288503497839\n","AUPR: mean: 0.4693988263607025, standard deviation: 0.024373149499297142\n","Loss: mean: 2.8511903285980225, standard deviation: 0.19298230111598969\n","training time per epoch: mean: 13.888402144114176\n","Evaluating parameter combination 12 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 1000, maxpooling False, optimization Adam, initial filters 32 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 1000, maxpooling False, optimization Adam, initial filters 32 and epochs 1\n","Results:\n","AUC: mean: 0.49537038803100586, standard deviation: 0.006547288503497839\n","AUPR: mean: 0.4693988263607025, standard deviation: 0.024373149499297142\n","Loss: mean: 2.608489751815796, standard deviation: 0.35012733936309814\n","training time per epoch: mean: 10.477694114049276\n","Evaluating parameter combination 13 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 100, maxpooling True, optimization Adam, initial filters 64 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 100, maxpooling True, optimization Adam, initial filters 64 and epochs 1\n","Results:\n","AUC: mean: 0.5214906334877014, standard deviation: 0.05020678788423538\n","AUPR: mean: 0.48155477643013, standard deviation: 0.04700107499957085\n","Loss: mean: 1.4839845895767212, standard deviation: 0.8897721171379089\n","training time per epoch: mean: 12.620611270268759\n","Evaluating parameter combination 14 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 100, maxpooling True, optimization Adam, initial filters 32 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 100, maxpooling True, optimization Adam, initial filters 32 and epochs 1\n","Results:\n","AUC: mean: 0.5092553496360779, standard deviation: 0.07624278962612152\n","AUPR: mean: 0.4910221993923187, standard deviation: 0.08486419171094894\n","Loss: mean: 0.3105935752391815, standard deviation: 0.05897204577922821\n","training time per epoch: mean: 10.081792116165161\n","Evaluating parameter combination 15 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 100, maxpooling False, optimization Adam, initial filters 64 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 100, maxpooling False, optimization Adam, initial filters 64 and epochs 1\n","Results:\n","AUC: mean: 0.49537038803100586, standard deviation: 0.006547288503497839\n","AUPR: mean: 0.4693988263607025, standard deviation: 0.024373149499297142\n","Loss: mean: 2.525850534439087, standard deviation: 0.3486946225166321\n","training time per epoch: mean: 13.69052267074585\n","Evaluating parameter combination 16 ...\n","Hyperparameter combination:\n","learn rate 0.001, batch size 3, dropout 0.5, dense nodes 100, maxpooling False, optimization Adam, initial filters 32 and epochs 1\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","Testing\n","Creating distributed data\n","Defining the model\n","Defining loss\n","Defining optimization\n","Defining the metrics\n","Training\n","INFO:tensorflow:Error reported to Coordinator: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n","    yield\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 231, in _call_for_each_replica\n","    **merge_kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 255, in wrapper\n","    return converted_call(f, args, kwargs, options=options)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 483, in converted_call\n","    options=options)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 457, in converted_call\n","    return _call_unconverted(f, args, kwargs, options, False)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 339, in _call_unconverted\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 633, in _distributed_apply\n","    var, apply_grad_to_update_var, args=(grad,), group=False))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2300, in update\n","    return self._update(var, fn, args, kwargs, group)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 657, in _update\n","    return distribute_utils.update_regroup(self, updates, group)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_utils.py\", line 165, in update_regroup\n","    return nest.map_structure(extended._local_results, regrouped)  # pylint: disable=protected-access\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\", line 635, in map_structure\n","    structure[0], [func(*x) for x in entries],\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\", line 635, in <listcomp>\n","    structure[0], [func(*x) for x in entries],\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 678, in _local_results\n","    def _local_results(self, val):\n","KeyboardInterrupt\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-e2b1e16f46cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m Hyperparam_Optimization(lr_list = LR_list, Batch_Size_list = BS_list, dropout_list = DP_list, \n\u001b[1;32m     21\u001b[0m                         \u001b[0mDense_Nodes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDN_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEMP_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOF_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_filters_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIF_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                         epochs_list = EP_list, savefile = dir_gridsearch)\n\u001b[0m","\u001b[0;32m<ipython-input-16-ccfba126d06f>\u001b[0m in \u001b[0;36mHyperparam_Optimization\u001b[0;34m(lr_list, Batch_Size_list, dropout_list, Dense_Nodes_list, MaxPool_list, optim_list, init_filters_list, epochs_list, savefile)\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         val_loss, val_auc, val_aupr = train_network(tr_images, tr_labels, val_images, val_labels, Drop_Prob = Dropout, Init_Filters = InitFilters, \n\u001b[1;32m     37\u001b[0m                                                                                     \u001b[0mDense_Nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_pooling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                                                                     learning_rate = tf.Variable(LearnRate, dtype=tf.float32), MAX_EPOCH = Epoch, SaveResults = False)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-14f9ca71c19e>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(TrainImages, TrainLabels, TestImages, TestLabels, Drop_Prob, Init_Filters, Dense_Nodes, extra_pooling, batch_size, loss_function, optim, learning_rate, MAX_EPOCH, SaveResults)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# go over all global batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_input_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dist_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# some testing has to be done at the last epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m                 ))\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/tmpab7ll7wk.py\u001b[0m in \u001b[0;36mtf__distributed_train_step\u001b[0;34m(dataset_inputs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtf__distributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distributed_train_step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_Step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__distributed_train_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Whitelisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     return mirrored_run.call_for_each_replica(\n\u001b[0;32m--> 585\u001b[0;31m         self._container_strategy(), fn, args, kwargs)\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m   def _configure(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_result\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mstop_on_exception\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=bare-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m               \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtt_captured_var_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             merge_result = threads[0].merge_fn(distribution, *merge_args,\n\u001b[0;32m--> 231\u001b[0;31m                                                **merge_kwargs)\n\u001b[0m\u001b[1;32m    232\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         options=options)\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misbuiltin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Whitelisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    631\u001b[0m                               \"update_\" + var.op.name, skip_on_eager=True):\n\u001b[1;32m    632\u001b[0m             update_ops.extend(distribution.extended.update(\n\u001b[0;32m--> 633\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2298\u001b[0m         fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2299\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2300\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2302\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m    655\u001b[0m             fn(v, *distribute_utils.select_replica_mirrored(i, args),\n\u001b[1;32m    656\u001b[0m                **distribute_utils.select_replica_mirrored(i, kwargs)))\n\u001b[0;32m--> 657\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_regroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_utils.py\u001b[0m in \u001b[0;36mupdate_regroup\u001b[0;34m(extended, updates, group)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mregrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMirrored\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregrouped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_grouped_mirrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_local_results\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplica_local_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m_local_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}